{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/toxic/')\n",
    "bs = 64\n",
    "data_lm = TextLMDataBunch.load(path,'toxic_lm',bs=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . - xxbos = = xxmaj on edit warring and xxup pov = = \\n\\n  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>does nt really matter since copyright law does nt apply to xxmaj iran . xxup iri 's xxunk law does nt recognize international copyright law and international copy right law does nt protect xxmaj iranian materials . xxmaj the image is already all over the net so i do nt see why it should n't be on xxmaj wiki . xxbos * xxmaj hi . xxmaj it was just a</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>to a tyrant ; nay to an immature little boy , despite your years ( oh and so many of them there are ) . xxmaj without hardly a glance you toss aside any changes you ca n't verify with the limitless tome you assume your mind to be . xxmaj and what of those whose revisions you 've mindlessly reverted , you dispatch to them on mass pseudo -</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>\" \" ) . \\n  \" xxbos \" \\n\\n  : : i have deleted the \" \" star - xxunk cast \" \" , as being superfluous : everybody can draw this conclusion on his own . xxmaj the \" \" splendid photography \" \" and \" \" unique , vibrant document \" \" are an almost xxunk consequence of this being a propaganda film , made by</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>will be more likely to associate the island with xxmaj europe rather than with xxmaj asia , so this was the reason for sorting the stub templates the way i did . xxmaj originally , we just used for all articles , but the material became so big that we broke it up by continent . i suspect that a stub template for xxmaj middle xxmaj east politicians will eventually</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cls = TextDataBunch.from_csv(path,'train_labeled2.csv',text_cols=['comment_text'],label_cols=['label'],label_delim=' ',vocab=data_lm.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj take that ! \\n\\n xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the</th>\n",
       "    <th>obscene;severe_toxic;toxic</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxup you xxup fucking xxup kike ! xxup don't xxup edit xxup things xxup you xxup have xxup no xxup idea xxup about ! xxup give xxup credit xxup where xxup it xxup 's xxup due ! xxup you xxup fucking xxup kike ! xxup don't xxup edit xxup things xxup you xxup have xxup no xxup idea xxup about ! xxup give xxup credit xxup where xxup it</th>\n",
       "    <th>insult;obscene;severe_toxic;toxic</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" xxmaj the following entries have been removed from the xxmaj dungeons & xxmaj dragons in popular culture article . xxmaj the reason is that they are trivial or minor references , and may not have a reliable source available . xxmaj if you want to restore these to the main article , please discuss on the talk page first . \\n\\n  xxmaj comics \\n  xxmaj xxunk</th>\n",
       "    <th>okay</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" . xxmaj if you want to talk about linguistic issues in the xxmaj spanish xxmaj state , or about terrorist bands linked to nationalism , do so at their right articles . xxmaj the way you try to shove those topics in an article about \" \" xxmaj nationalities in xxmaj spain xxrep 4 \" looks like youÂ´re trying to inject your personal , xxunk to those xxunk</th>\n",
       "    <th>okay</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n  novaseminary pov pushing , and section blanking . xxmaj so everyone is aware of his pov editing , i have copied some of his history here . i ask other editors not to restore his versions as they are pov and section blanking . \\n xxmaj here is a little histoy on xxunk . xxmaj more can easily be found . i include it here to</th>\n",
       "    <th>okay</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_cls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creat multiclass accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_02 = partial(accuracy_thresh, thresh=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_cls, drop_mult=0.5, metrics=[acc_02])\n",
    "learn.load_encoder('toxic_lm_finetuned_enc')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 08:59 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.099505</th>\n",
       "    <th>0.078640</th>\n",
       "    <th>0.960833</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_cls_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('toxic_cls_finetuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 23:13 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.070246</th>\n",
       "    <th>0.058520</th>\n",
       "    <th>0.971621</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.054977</th>\n",
       "    <th>0.060694</th>\n",
       "    <th>0.975430</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(2, slice(2e-2/(2.6**4),2e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_cls_finetuned2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: MultiCategoryList (127656 items)\n",
       "[MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay]...\n",
       "Path: /data/toxic\n",
       "x: TextList (127656 items)\n",
       "[Text xxbos xxmaj really ? xxmaj ya do n't say ? xxmaj who 'd a xxunk ?, Text xxbos \" \n",
       "\n",
       "  xxmaj reverting xxmaj vandalism \n",
       "\n",
       " xxmaj is there a hot key or something that i can use to easily describe what i am doing in the \" \" xxmaj edit xxmaj summary \" \" when i revert vandalism or do i need to physically type the information every time ? \", Text xxbos \" \n",
       " xxmaj improvement \n",
       " xxmaj please look at the last addition that improves the discussion about oxyhydrogen and the \" \" bad word \" \" xxup xxunk . xxmaj steve , you always say that we need sources . i have placed several peer reviewed sources and someone just cancelled . i made a mistake of not having this note written before , but , i had no time yesterday . xxmaj apologies xxrep 4 . i am adding it now and i feel that , instead of just removing my edits , the page should be improved to keep in the spirit of xxmaj wikipedia and the efforts of xxmaj steve xxmaj baker . \n",
       " xxmaj xxunk . \", Text xxbos oh and i m not a tool i mean who uses those words now xxunk i m no tool or are you racist and trying to say the xxunk is nothing but a tool box huh hey why do nt u get out of prep rock xxmaj city and come down and play with the big xxunk there is no mention of xxmaj london exept for 2 times and xxmaj xxunk xxmaj city was mentioned from xxup xxunk witch is xxup before xxup manhunt to xxup xxunk they mentioned it in xxunk game seeing as xxmaj london only got 2 refernces this makes it ruled out and making xxmaj xxunk xxmaj city and the now not made to xxup 3d xxmaj anywhere xxmaj city from xxup xxunk i did nt change anything ok xxmaj cat so i your gon na say junk come do it xxmaj xxunk all you people need to point your fingers and say that s the bad guy this is the last time xxunk gon na see a bad guy like this so say goodnight to the xxunk oh and i just almost forgot r * is in xxup nyc ok cockroach not in xxmaj london meng if you do nt xxunk me fly down to xxup nyc and pay a vist to xxmaj sam xxmaj xxunk for your self xxunk, Text xxbos xxmaj xxunk , can you provide a source which makes this link ? xxmaj otherwise it is original research , or a synthesis . xxmaj scott xxmaj mac]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: MultiCategoryList (31915 items)\n",
       "[MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay]...\n",
       "Path: /data/toxic\n",
       "x: TextList (31915 items)\n",
       "[Text xxbos \" \n",
       " xxup an , are you unable to discern the difference between an exchange directly related to editing the article and a bit of discussion only indirectly related to editing ? xxmaj except for you , we are all of us here a bit off - topic . ( xxmaj sorry ) xxmaj but since you mention it , given the number of testimonies by xxmaj scientologist that are available , it is not minority at all nor undue weight . xxmaj one would need only phrase it as \" \" xxmaj many xxmaj scientologists say they have experienced . . . \" \" xxmaj we are not talking \" \" science \" \" here , we are talking subjective experience and if ten thousand people say they saw the xxmaj mother of xxmaj god in a window pane then we say that \" \" ten thousand people say they saw the xxmaj mother of xxmaj god in a window pane . \" \" \", Text xxbos \" \n",
       "\n",
       " xxmaj thanks xxmaj xxunk that would be great , just chuck the info on my talk page please , and thanks xxmaj soap much appreciated . xxmaj pro \", Text xxbos \" \n",
       "\n",
       " xxmaj the innate immunity , i.e. xxunk , is not particularly good at dealing with viruses . xxmaj in fact , it has been argued , in xxmaj delves and xxmaj xxunk for starters , that the adaptive immune system evolved to defend us against these little bastards . xxmaj your are right about xxunk mopping up after wards , but it is the lymphocytes that control virus infections . xxmaj so , not really part of this article as such . xxmaj but your are right . xxmaj some readers will wonder about viruses , so the article needs to mention them more , if only to say that xxunk ca n't handle them alone . xxmaj this will not be difficult to add and i will write it today . xxmaj with regard to green snot during a viral infection â secondary bacterial infections , xxunk infecting the damaged tissues , are no doubt to blame . xxmaj talk \", Text xxbos xxmaj an illustration from the mirror scene would be excellent , provided the xxup fu deletionists do n't zap it . xxmaj what 's up , xxmaj doc ?, Text xxbos i have merged it with xxmaj separatist movements of xxmaj india and added some stuff on the xxmaj xxunk xxmaj xxunk]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of BCEWithLogitsLoss(), metrics=[functools.partial(<function accuracy_thresh at 0x7fc66ebfd488>, thresh=0.2)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: MultiCategoryList (127656 items)\n",
       "[MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay]...\n",
       "Path: /data/toxic\n",
       "x: TextList (127656 items)\n",
       "[Text xxbos xxmaj really ? xxmaj ya do n't say ? xxmaj who 'd a xxunk ?, Text xxbos \" \n",
       "\n",
       "  xxmaj reverting xxmaj vandalism \n",
       "\n",
       " xxmaj is there a hot key or something that i can use to easily describe what i am doing in the \" \" xxmaj edit xxmaj summary \" \" when i revert vandalism or do i need to physically type the information every time ? \", Text xxbos \" \n",
       " xxmaj improvement \n",
       " xxmaj please look at the last addition that improves the discussion about oxyhydrogen and the \" \" bad word \" \" xxup xxunk . xxmaj steve , you always say that we need sources . i have placed several peer reviewed sources and someone just cancelled . i made a mistake of not having this note written before , but , i had no time yesterday . xxmaj apologies xxrep 4 . i am adding it now and i feel that , instead of just removing my edits , the page should be improved to keep in the spirit of xxmaj wikipedia and the efforts of xxmaj steve xxmaj baker . \n",
       " xxmaj xxunk . \", Text xxbos oh and i m not a tool i mean who uses those words now xxunk i m no tool or are you racist and trying to say the xxunk is nothing but a tool box huh hey why do nt u get out of prep rock xxmaj city and come down and play with the big xxunk there is no mention of xxmaj london exept for 2 times and xxmaj xxunk xxmaj city was mentioned from xxup xxunk witch is xxup before xxup manhunt to xxup xxunk they mentioned it in xxunk game seeing as xxmaj london only got 2 refernces this makes it ruled out and making xxmaj xxunk xxmaj city and the now not made to xxup 3d xxmaj anywhere xxmaj city from xxup xxunk i did nt change anything ok xxmaj cat so i your gon na say junk come do it xxmaj xxunk all you people need to point your fingers and say that s the bad guy this is the last time xxunk gon na see a bad guy like this so say goodnight to the xxunk oh and i just almost forgot r * is in xxup nyc ok cockroach not in xxmaj london meng if you do nt xxunk me fly down to xxup nyc and pay a vist to xxmaj sam xxmaj xxunk for your self xxunk, Text xxbos xxmaj xxunk , can you provide a source which makes this link ? xxmaj otherwise it is original research , or a synthesis . xxmaj scott xxmaj mac]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: MultiCategoryList (31915 items)\n",
       "[MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay, MultiCategory okay]...\n",
       "Path: /data/toxic\n",
       "x: TextList (31915 items)\n",
       "[Text xxbos \" \n",
       " xxup an , are you unable to discern the difference between an exchange directly related to editing the article and a bit of discussion only indirectly related to editing ? xxmaj except for you , we are all of us here a bit off - topic . ( xxmaj sorry ) xxmaj but since you mention it , given the number of testimonies by xxmaj scientologist that are available , it is not minority at all nor undue weight . xxmaj one would need only phrase it as \" \" xxmaj many xxmaj scientologists say they have experienced . . . \" \" xxmaj we are not talking \" \" science \" \" here , we are talking subjective experience and if ten thousand people say they saw the xxmaj mother of xxmaj god in a window pane then we say that \" \" ten thousand people say they saw the xxmaj mother of xxmaj god in a window pane . \" \" \", Text xxbos \" \n",
       "\n",
       " xxmaj thanks xxmaj xxunk that would be great , just chuck the info on my talk page please , and thanks xxmaj soap much appreciated . xxmaj pro \", Text xxbos \" \n",
       "\n",
       " xxmaj the innate immunity , i.e. xxunk , is not particularly good at dealing with viruses . xxmaj in fact , it has been argued , in xxmaj delves and xxmaj xxunk for starters , that the adaptive immune system evolved to defend us against these little bastards . xxmaj your are right about xxunk mopping up after wards , but it is the lymphocytes that control virus infections . xxmaj so , not really part of this article as such . xxmaj but your are right . xxmaj some readers will wonder about viruses , so the article needs to mention them more , if only to say that xxunk ca n't handle them alone . xxmaj this will not be difficult to add and i will write it today . xxmaj with regard to green snot during a viral infection â secondary bacterial infections , xxunk infecting the damaged tissues , are no doubt to blame . xxmaj talk \", Text xxbos xxmaj an illustration from the mirror scene would be excellent , provided the xxup fu deletionists do n't zap it . xxmaj what 's up , xxmaj doc ?, Text xxbos i have merged it with xxmaj separatist movements of xxmaj india and added some stuff on the xxmaj xxunk xxmaj xxunk]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchRNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of BCEWithLogitsLoss(), metrics=[functools.partial(<function accuracy_thresh at 0x7fc66ebfd488>, thresh=0.2)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])\n",
       "bptt: 70\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('toxic_cls_finetuned2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ran out of mem again, reload model and run.\n",
    "\n",
    "whats really going on here is that when I unfreeze more layers I'm giving the gpu a ton more params to compute on each pass.. this means I have to reduce the batch size from what was working for finetuning the first layer to finetuning 3 layers.\n",
    "\n",
    "found this section of the forum talking about it:\n",
    "\n",
    "```data = ImageClassifierData_from_paths(PATH, bs=new_bs, tfms=tfms_from_model(arch,sz))\n",
    "learn.precompute = False\n",
    "learn.set_data(data)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3bf0abb3b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/toxic/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextLMDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'toxic_lm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_labeled2.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_delim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "bs=48\n",
    "path = Path('/data/toxic/')\n",
    "data_lm = TextLMDataBunch.load(path,'toxic_lm',bs=bs)\n",
    "data_cls = TextDataBunch.from_csv(path,'train_labeled2.csv',text_cols=['comment_text'],label_cols=['label'],label_delim=' ',vocab=data_lm.vocab)\n",
    "\n",
    "acc_02 = partial(accuracy_thresh, thresh=0.2)\n",
    "\n",
    "learn = text_classifier_learner(data_cls, drop_mult=0.7, metrics=[acc_02])\n",
    "learn.load_encoder('toxic_lm_finetuned_enc')\n",
    "learn.load('toxic_cls_finetuned2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62907"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in learn.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2546107"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in learn.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1522' class='' max='3989', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      38.15% [1522/3989 03:31<05:43 0.0555]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, slice(1e-6/(2.6**4),3e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 28:23 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.062232</th>\n",
       "    <th>0.074586</th>\n",
       "    <th>0.974240</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.068340</th>\n",
       "    <th>0.047503</th>\n",
       "    <th>0.976666</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.058352</th>\n",
       "    <th>0.053249</th>\n",
       "    <th>0.974643</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, slice(3e-3/(2.6**4),3e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_cls_finetuned2c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiBatchRNNCore(\n",
       "  (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1150, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1150, 1150, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1150, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find how many params are actually trainable in a given model based on which ones aren't frozen. this wil help in the future when trying to figure out how many can be put onto the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19065307"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in learn.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy_thresh</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3989', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 66.62 MiB (GPU 0; 5.93 GiB total capacity; 4.80 GiB already allocated; 67.38 MiB free; 250.42 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-644a31004af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     21\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 178\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtb_clear_frames\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ref_free_exc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# must!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0;31m# re-raises the exact last exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtb_clear_frames\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 66.62 MiB (GPU 0; 5.93 GiB total capacity; 4.80 GiB already allocated; 67.38 MiB free; 250.42 MiB cached)"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_cls_finetuned3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for kicks, try it out on some existing samples of data, and make up some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiCategory insult;obscene;severe_toxic;toxic,\n",
       " tensor([0., 1., 1., 0., 1., 0., 1.]),\n",
       " tensor([0.0056, 0.6599, 0.9731, 0.0022, 0.5382, 0.0337, 0.9966]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiCategory insult;obscene;toxic,\n",
       " tensor([0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([0.0073, 0.7812, 0.7074, 0.0093, 0.0613, 0.0104, 0.9850]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"You are the shittiest editor I've ever met in my life. Use your dumbass little fingers to go pick your butt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiCategory okay,\n",
       " tensor([0., 0., 0., 1., 0., 0., 0.]),\n",
       " tensor([2.9943e-05, 1.6462e-04, 1.1089e-04, 9.9961e-01, 2.5609e-05, 8.7224e-05,\n",
       "         3.5441e-04]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Thanks for taking the effort to help out ont his the other day, you caught a few errors I missed :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiCategory obscene;threat;toxic,\n",
       " tensor([0., 0., 1., 0., 0., 1., 1.]),\n",
       " tensor([0.0194, 0.4015, 0.7755, 0.0053, 0.2811, 0.9550, 0.9923]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I'm gunna come kill your sorry ass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try and predict the values of test and score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.994265e-05, 1.646208e-04, 1.108864e-04, 9.996081e-01, 2.560941e-05, 8.722375e-05, 3.544122e-04], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(learn.predict(\"Thanks for taking the effort to help out ont his the other day, you caught a few errors I missed :)\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(row,learn):\n",
    "    pred = np.array(learn.predict(row['comment_text'])[2])\n",
    "    # ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    # return pred[6],pred[4],pred[2],pred[5],pred[1],pred[0] # pred[3] is okay\n",
    "    return pred\n",
    "\n",
    "model_pred_set = partial(model_pred,learn=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label_map = {'identity_hate':0, 'insult':1, 'obscene':2, 'severe_toxic':4, 'threat':5, 'toxic':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_df['pred'] = test_df.apply(model_pred_set,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    test_df[label] = test_df['pred'].apply(lambda x: x[model_label_map[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['id','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('/data/toxic/ft2c.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>pred</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>[0.6199746, 0.8803529, 0.9456099, 0.004148753,...</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.287364</td>\n",
       "      <td>0.945610</td>\n",
       "      <td>0.069803</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>0.619975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>[4.984817e-05, 0.00025699934, 0.00024182763, 0...</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>[6.592622e-05, 0.00019218664, 0.0002554554, 0....</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>[2.172245e-05, 8.874213e-05, 8.6309476e-05, 0....</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>[0.0004767867, 0.0020870555, 0.0019417837, 0.9...</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                                pred     toxic  severe_toxic  \\\n",
       "0  [0.6199746, 0.8803529, 0.9456099, 0.004148753,...  0.992484      0.287364   \n",
       "1  [4.984817e-05, 0.00025699934, 0.00024182763, 0...  0.000699      0.000093   \n",
       "2  [6.592622e-05, 0.00019218664, 0.0002554554, 0....  0.000522      0.000076   \n",
       "3  [2.172245e-05, 8.874213e-05, 8.6309476e-05, 0....  0.000119      0.000022   \n",
       "4  [0.0004767867, 0.0020870555, 0.0019417837, 0.9...  0.009781      0.000581   \n",
       "\n",
       "    obscene    threat    insult  identity_hate  \n",
       "0  0.945610  0.069803  0.880353       0.619975  \n",
       "1  0.000242  0.000057  0.000257       0.000050  \n",
       "2  0.000255  0.000038  0.000192       0.000066  \n",
       "3  0.000086  0.000060  0.000089       0.000022  \n",
       "4  0.001942  0.000554  0.002087       0.000477  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[0,'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>(a, b, c, d, e, f)</th>\n",
       "      <th>i</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.99248356, 0.28736445, 0.9456099, 0.06980274...</td>\n",
       "      <td>[0.99248356, 0.28736445, 0.9456099, 0.06980274...</td>\n",
       "      <td>[0.6199746, 0.8803529, 0.9456099, 0.004148753,...</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.287364</td>\n",
       "      <td>0.945610</td>\n",
       "      <td>0.069803</td>\n",
       "      <td>0.880353</td>\n",
       "      <td>0.619975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0006987686, 9.297005e-05, 0.00024182763, 5....</td>\n",
       "      <td>[0.0006987686, 9.297005e-05, 0.00024182763, 5....</td>\n",
       "      <td>[4.984817e-05, 0.00025699934, 0.00024182763, 0...</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0005222669, 7.638931e-05, 0.0002554554, 3.7...</td>\n",
       "      <td>[0.0005222669, 7.638931e-05, 0.0002554554, 3.7...</td>\n",
       "      <td>[6.592622e-05, 0.00019218664, 0.0002554554, 0....</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0001187438, 2.240059e-05, 8.6309476e-05, 5....</td>\n",
       "      <td>[0.0001187438, 2.240059e-05, 8.6309476e-05, 5....</td>\n",
       "      <td>[2.172245e-05, 8.874213e-05, 8.6309476e-05, 0....</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.009780869, 0.0005805743, 0.0019417837, 0.00...</td>\n",
       "      <td>[0.009780869, 0.0005805743, 0.0019417837, 0.00...</td>\n",
       "      <td>[0.0004767867, 0.0020870555, 0.0019417837, 0.9...</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                       comment_text  \\\n",
       "0      0  [0.99248356, 0.28736445, 0.9456099, 0.06980274...   \n",
       "1      1  [0.0006987686, 9.297005e-05, 0.00024182763, 5....   \n",
       "2      2  [0.0005222669, 7.638931e-05, 0.0002554554, 3.7...   \n",
       "3      3  [0.0001187438, 2.240059e-05, 8.6309476e-05, 5....   \n",
       "4      4  [0.009780869, 0.0005805743, 0.0019417837, 0.00...   \n",
       "\n",
       "                                  (a, b, c, d, e, f)  \\\n",
       "0  [0.99248356, 0.28736445, 0.9456099, 0.06980274...   \n",
       "1  [0.0006987686, 9.297005e-05, 0.00024182763, 5....   \n",
       "2  [0.0005222669, 7.638931e-05, 0.0002554554, 3.7...   \n",
       "3  [0.0001187438, 2.240059e-05, 8.6309476e-05, 5....   \n",
       "4  [0.009780869, 0.0005805743, 0.0019417837, 0.00...   \n",
       "\n",
       "                                                   i     toxic  severe_toxic  \\\n",
       "0  [0.6199746, 0.8803529, 0.9456099, 0.004148753,...  0.992484      0.287364   \n",
       "1  [4.984817e-05, 0.00025699934, 0.00024182763, 0...  0.000699      0.000093   \n",
       "2  [6.592622e-05, 0.00019218664, 0.0002554554, 0....  0.000522      0.000076   \n",
       "3  [2.172245e-05, 8.874213e-05, 8.6309476e-05, 0....  0.000119      0.000022   \n",
       "4  [0.0004767867, 0.0020870555, 0.0019417837, 0.9...  0.009781      0.000581   \n",
       "\n",
       "    obscene    threat    insult  identity_hate  \n",
       "0  0.945610  0.069803  0.880353       0.619975  \n",
       "1  0.000242  0.000057  0.000257       0.000050  \n",
       "2  0.000255  0.000038  0.000192       0.000066  \n",
       "3  0.000086  0.000060  0.000089       0.000022  \n",
       "4  0.001942  0.000554  0.002087       0.000477  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'expand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-c8fe4328c026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'expand'"
     ]
    }
   ],
   "source": [
    "a['comment_text'].expand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and unfreeze and train the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 15:17 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.240424</th>\n",
       "    <th>0.155204</th>\n",
       "    <th>0.943160</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.217462</th>\n",
       "    <th>0.153421</th>\n",
       "    <th>0.943960</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_cls_fulltuned3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
