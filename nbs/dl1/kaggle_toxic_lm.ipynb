{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/toxic/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only contains one csv file, let's have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text toxic severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   NaN          NaN   \n",
       "1  D'aww! He matches this background colour I'm s...   NaN          NaN   \n",
       "2  Hey man, I'm really not trying to edit war. It...   NaN          NaN   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   NaN          NaN   \n",
       "4  You, sir, are my hero. Any chance you remember...   NaN          NaN   \n",
       "\n",
       "  obscene threat insult identity_hate label  \n",
       "0     NaN    NaN    NaN           NaN  okay  \n",
       "1     NaN    NaN    NaN           NaN  okay  \n",
       "2     NaN    NaN    NaN           NaN  okay  \n",
       "3     NaN    NaN    NaN           NaN  okay  \n",
       "4     NaN    NaN    NaN           NaN  okay  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'small_train_labeled2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n",
       "       'Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...',\n",
       "       \"Bye! \\n\\nDon't look, come or think of comming back! Tosser.\",\n",
       "       \"You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!\",\n",
       "       'FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!',\n",
       "       \"I'm Sorry \\n\\nI'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82\",\n",
       "       \"GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\",\n",
       "       'Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!',\n",
       "       '=Tony Sidaway is obviously a fistfuckee. He loves an arm up his ass.',\n",
       "       \"My Band Page's deletion. You thought I was gone. \\n\\nDeleting the comment I posted on your 'talk page' does not delete my feelings for your hasty decision to delete my page. You, sir, are still a cock-sucking douche fuck. Sit back for a second and think about what your life has become. ............ Done? That didn't take long did it? Nope. Because, as I am most certainly aware, your life is a shitstorm of sitting in front of the computer masturbating to fictional creatures. Your attempts to get rid of me are mediocre at best. You are constantly sucking the dick of failure. You don't want a personal attack, huh? Well, too bad, Fuckcock McDickerson. You've got one. From me. You can go ahead and delete my profile from wikipedia. I'll just make another one and come right back to 'Syrthiss's talk page and insult the dick off of you. How could you shatter the dreams of an innocent eighteen year old college freshman trying to make a name for his band. Does that make you happy? Fucking with people because you're an overweight, single, old man in a dead-end job. Did you spot that perhaps someone else was going to follow his dreams and you were trying to hold him back so somebody else could suffer like you? Yes you did. I don't make empty threats, so I won't be saying anything along the lines of 'i'll hurt you' or 'i'll eat the children from within your sister's womb', but I will say that you are a asshole, son-of-a-bitch, mother fucking cock sucker. So, go eat some more food and drown your sorrows you premature ejaculating, bald headed fuck.\\n\\nYou should do something nice for yourself, maybe go grab a couple of Horny Goat Weeds from your local convenience store and jack off for a little longer than three minutes tonight.\\n\\nSincerely,\\nAn Asshole That's Better Than You In Every Way.\",\n",
       "       \"Why can't you believe how fat Artie is? Did you see him on his recent appearence on the Tonight Show with Jay Leno? He looks absolutely AWFUL! If I had to put money on it, I'd say that Artie Lange is a can't miss candidate for the 2007 Dead pool!   \\n\\n  \\nKindly keep your malicious fingers off of my above comment, . Everytime you remove it, I will repost it!!!\",\n",
       "       \"All of my edits are good.  Cunts like you who revert good edits because you're too stupid to understand how to write well , and then revert other edits just because you've decided to bear a playground grudge, are the problem.  Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159\",\n",
       "       'Hi! I am back again!\\nLast warning!\\nStop undoing my edits or die!',\n",
       "       \"Would you both shut up, you don't run wikipedia, especially a stupid kid.\",\n",
       "       'A pair of jew-hating weiner nazi schmucks.',\n",
       "       '\"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS NUMBER ONE!! But he is clearly listed as being \"\"second only to Batman\"\" and a \"\"master detective and martial artist\"\" and been trained in all the mentioned combat discplines. No need to mention in skills/abilities about the battles he\\'s lost and won because thats not what an encylopia is supposed to do. \\n\\nAlso, what your problem is your going by low end showings and not HIGH end showings where he\\'s proven more than a match for a meta like Slade and pinned Shiva down in one of his earliest appearences.\\n \"',\n",
       "       '\"\\n\\nUNBLOCK ME OR I\\'LL GET MY LAWYERS ON TO YOU FOR BLOCKING MY CONSTITUTIONAL RIGHT TO FREE SPEECH\"',\n",
       "       \"You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.\",\n",
       "       \"I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms\",\n",
       "       \"REPLY ABOVE:\\nThat was me, loser. The UN defines Vietnam to be part of Southeast Asia. And far as I know Vietnam is part of ASEAN, and used to be part of French Indochina with Laos and all those shit countries Anyway your culture has always been more influenced by SEA than Han Chinese (as in proper Yangtze Han Chinese, not the fringe indigenous tribes in Guangzhou/Guangxi). \\n\\nJust admit that you vietnamese are all a bunch of wannabe crap people. ALL the east asian people I've spoken to thinks of Vietnam as a very integral part of SEA, and we all think you're backward, dirty and speak in a horrible swearing language. Doesn't matter what crap you spout on Wikipedia, won't change the way people in the real world think.\",\n",
       "       \"you are a stupid fuck \\n\\nand your mother's cunt stinks\",\n",
       "       'Your blatant POV pushing \\n\\nNeither of you guys has made any contribution to this Italian history article other than to shove your unhistorical unconstructive modern POV in my face.\\nThis is a HISTORY article. HISTORY.\\nHave you heard of that?\\nThis is the reason why so many people get pissed off about the pedantry and idiocy and triviality of Wikipedia.\\nJ*sus. Get a f*cking life.',\n",
       "       'Give me a permanat block raseac....!!! remember me....!!! Muslims dont you worry for these images they are trying to hurt us but they cant look these images are fake and have nothing to do with Islam or our prophet even their article is so lame wikipedia is not an authentic source its an encyclopedia for the kids which has not authenticity anyone can edit or write whatever they think...just like raeasc you can see he does not knows what Islam is and he talks about it so forget about wiki its lame they have no authenticity...i recommend they should add pissed christ in jessus article....they should...',\n",
       "       'Fuck you, block me, you faggot pussy!',\n",
       "       'Kill all niggers. \\n\\nI have hard, that others have said this.. should this be included? That racists sometimes say these.',\n",
       "       \"Burn Deck \\n\\nIf that'd guy's burn deck is like what I think it is than he is in for a blrude awakening!!! Leviathan motherfucker!!!\",\n",
       "       'u r a tw@ fuck off u gay boy.U r smelly.Fuck ur mum poopie'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] != 'okay']['comment_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of the dataset and number of samples in each type of comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id','comment_text'],axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a few toxic comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n",
       "       'Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...',\n",
       "       \"Bye! \\n\\nDon't look, come or think of comming back! Tosser.\",\n",
       "       \"You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!\",\n",
       "       'FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['toxic'] == 1].loc[:,'comment_text'].head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a few severe toxic comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n",
       "       'Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!',\n",
       "       \"you are a stupid fuck \\n\\nand your mother's cunt stinks\", 'Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181',\n",
       "       'What a motherfucking piece of crap those fuckheads for blocking us!'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['severe_toxic'] == 1].loc[:,'comment_text'].head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a few obscene comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK',\n",
       "       \"You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!\",\n",
       "       'FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!',\n",
       "       \"GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\",\n",
       "       'Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['obscene'] == 1].loc[:,'comment_text'].head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(TextDataBunch.from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unfortunately can't figure out how to create a multi-class slassifier, so will just create a model to predict toxic comments alone. need to figure out further work with fastai `TextDataBunch` to load multi-class from multiple columns. Otherwise load in pytorch text by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "labels = ['toxic']#,'threat']\n",
    "data_lm = TextDataBunch.from_csv(path,'train.csv',label_cols=labels)#,classes=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj take that ! \\n\\n xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup huge xxup faggot xxup</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj you are asshole master of deletions \\n  22:18 , 17 xxmaj march 2013 ( diff | hist ) . . ( + xxunk . . xxmaj user talk : patgallacher ‎ ( xxmaj notifying author of deletion nomination for xxmaj patricia xxmaj walsh ) ( current ) \\n  22:18 , 17 xxmaj march 2013 ( diff | hist ) . . ( + xxunk . .</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n  xxmaj you xxmaj people ... \\n ... xxmaj are hoping , begging and wishing for xxunk , respect a title that you did not earn , go by on your own and are not deserving of . xxmaj you did not build the xxup us , you had the xxmaj spanish xxmaj empire and it failed , not you come here by crossing the border and</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n  xxmaj one xxup mo ' time for the kids in the back ... \\n\\n xxup just ca n’t let go of a few items , huh ? \\n\\n xxmaj okay from the top : \\n 1 ) xxmaj my info on the xxup glaad awards and the xxup eisner xxmaj nominations came from xxmaj winick ’s website . xxup but is that ’s not good enough</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('toxic_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataBunch.load(path,'toxic_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj take that ! \\n\\n xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n xxmaj why wikipedia 's mod system does not work ;) \\n\\n http : / / www.usatoday.com / tech / columnist / xxunk / 2006 - 09 - xxunk - of - xxunk \\n\\n xxmaj techies hot on concept of ' wisdom of crowds , ' but it has some pitfalls ... \\n xxmaj posted 9 / 12 / 2006 xxunk xxup pm xxup et \\n\\n xxmaj internet</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n xxmaj hi xxmaj xxunk - xxmaj the most important thing in any article on a historical person , whether it is for xxmaj wikipedia or an old - fashioned encyclopedia , is accuracy . xxmaj that accuracy goes beyond just the facts and dates that are presented , and goes on to include any photographic images that are purported to be the individual in question . xxmaj</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos = = xxmaj please read unblock request carefully \\n\\n xxmaj this why i ask whoever read my request to read it carefully , i will address your points in order of when your address them . \\n\\n xxmaj first , your said that you will work with the editor to help make the page notable , yet that is what i was asking for throughout the entire debate before</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n xxup you xxup people xxup are xxup at xxup it xxup again . \\n\\n xxmaj he first started achieving major public notoriety in early 2007 , when he made complaints of harassment at xxmaj columbia xxmaj university , against students who allegedly called him a \" \" baby killer \" \" for being in the military \\n\\n xxmaj no , he first made his complaints in early</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of processing we make texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
    "\n",
    "- we need to take care of punctuation\n",
    "- some words are contractions of two different words, like isn't or don't\n",
    "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
    "\n",
    "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj take that ! \\n\\n xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the xxup ass xxup in xxup the</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos { { unblock| xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is a moron in an xxmaj oxymoron xxmaj oxymoron is</th>\n",
       "    <th>1</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n xxmaj actually , i do n't think it 's particularly ' enlightening ' at all ! xxmaj first , the essay implies that a person may be inclined to view a number of edits as coming from ' the same person ' . i view that implication as an example of a ' straw - man argument ' : a person builds up an ( intentionally weak</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n  xxmaj newly xxmaj discovered xxmaj documentary xxmaj evidence xxmaj that xxmaj affects this xxmaj article 's xxmaj accuracy \\n\\n i have recently found a 1979 booklet of questions and answers with xxmaj rawat printed and distributed by xxmaj divine xxmaj light xxmaj mission , xxmaj inc. which bears heavily on some of the issues central to this article . xxmaj this document was published at least</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n i did n't write the sentence about the biblical references , i merely supplied them . i do n't remember who wrote the sentence . xxmaj however , a federal circuit court , wrote , ( one of my deleted references ) : \\n\\n xxmaj the following was excerpted from xxmaj xxunk v. xxmaj law , 142 xxmaj xxunk xxunk ( 2d xxmaj cir . 1998 )</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TextClasDataBunch.load(path,'toxic_lm')\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos blocked . xxmaj if i was aware that the conduct i was to have undertaken was to get me permanently blocked form ever edit again i would not have done it i think a warning first would have been good , as i have seen that to be standard practice on other people have looked at who have been"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like his: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unkown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at list twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " 'the']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj raking bishops \n",
       "\n",
       " xxmaj the page has good material on several tactical and strategic motifs involving bishops . xxmaj we should probably have a brief discussion of raking bishops , and single and double bishop sacrifices ."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bishops'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[8123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,     4, 38926,  8123,    22,     4,     9,    49,    64,   126])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data block API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
    "\n",
    "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the variaous arguments to pass will appear in the step they're revelant, so it'll be more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TextList.from_csv(path, 'small_train.csv', cols='comment_text')\n",
    "#                 .split_from_df(col=1)\n",
    "                .no_split()\n",
    "                .label_from_df(cols=[2])\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj xxunk , xxmaj hello xxmaj witzeman \\n\\n xxunk \\n xxmaj xxunk : ~ | xxunk xxunk xxunk xxunk xxunk xxunk xxunk • xxunk # xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk “ xxunk ” xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n  xxmaj randroide xxmaj answers to \" \" xxmaj next xxmaj xxunk \" \" \\n\\n xxmaj guys , i do not see you xxunk xxunk to xxmaj wikipedia : xxmaj xxunk for mediation . \\n\\n i can not do this job because i always xxunk from \" \" xxunk \" \" xxunk xxunk - access , and following those xxunk could xxunk in new , xxunk ,</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" = = xxmaj xxunk and xxunk of personalities = = \\n xxmaj xxunk . xxmaj your input to xxmaj culture of xxmaj lithuania is xxunk . \\n xxmaj some problems of xxunk personalities or xxunk them to certain well - known xxunk systems may xxunk here . i propose a quite xxunk xxunk of it , where definition may not be xxunk with one certain word . xxmaj</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n\\n xxup xxunk , you said you wanted to talk \\n\\n xxmaj at the xxunk of the lead section you have xxunk : \\n\\n \" \" xxmaj its xxunk xxunk in xxunk that the skyhook concept could be xxunk competitive with what is xxunk thought to be xxunk using a space xxunk , but the skyhook is not competitive with other rotating tether concepts . xxmaj in addition</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos \" \\n xxmaj fair use rationale for xxmaj image : xxmaj wonju.jpg \\n\\n xxmaj thanks for xxunk xxmaj image : xxmaj wonju.jpg . i notice the image page xxunk that the image is being used under fair use but there is no explanation or rationale as to why its use in xxmaj wikipedia articles xxunk fair use . xxmaj in addition to the xxunk fair use template , you</th>\n",
       "    <th>0</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train lm on all text data available (including test.csv) so I will join both train and test together, only keeping the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/data/toxic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/data/toxic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lm_text_df = pd.concat([train_df['comment_text'],test_df['comment_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_lm_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153159    . \\n i totally agree, this stuff is nothing bu...\n",
       "153160    == Throw from out field to home plate. == \\n\\n...\n",
       "153161    \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
       "153162    \" \\n\\n == \"\"One of the founding nations of the...\n",
       "153163    \" \\n :::Stop already. Your bullshit is not wel...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_lm_text_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lm_text_df.to_csv('/data/toxic/full_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/data_block.py:475: UserWarning: You are labelling your items with CategoryList.\n",
      "Your valid set contained the folowing unknown labels, the corresponding items have been discarded.\n",
      "150519, 103439, 157917, 118711, 154274...\n",
      "  if getattr(ds, 'warn', False): warn(ds.warn)\n"
     ]
    }
   ],
   "source": [
    "labels = ['toxic']#,'threat']\n",
    "data_lm = TextDataBunch.from_csv(path,'full_lm.csv')#,classes=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('toxic_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab the full dataset for what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextDataBunch.load(path,'toxic_lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
    "\n",
    "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipeia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviex lefts by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust a little bit the parameters of our model. Plus there might be some words extremely common in that dataset that were barely present in wikipedia, and therefore might no be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250187"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48861"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
    "\n",
    "The line before being a bit long, we want to load quickly the final ids by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48\n",
    "\n",
    "data_lm = TextLMDataBunch.load(path,'toxic_lm',bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . - xxbos = = xxmaj on edit warring and xxup pov = = \\n\\n  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>xxmaj signpost \\n { | align=\"\"center \" \" cellspacing=\"\"20 \" \" width=90 % style=\"\"background - color : transparent ; \" \" \\n | width=50 % | xxmaj arbitration xxmaj committee elections open \\n | width=50 % | xxmaj the xxmaj seigenthaler incident : xxmaj one year later \\n |- \\n | width=50 % | xxmaj wikimedia celebrates xxmaj commons milestone , plans fundraiser \\n | width=50 % | xxmaj wikipedia</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>or can you do it as an administrator , so that the history moves with it ? xxmaj there was a revert move xxunk , but i do n't see it anymore . i am trying to create redirects from full names and vice versa , and find missing middle names for people . xxbos : xxmaj hi ! xxmaj many thanks this would be great . i have also</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>will be more likely to associate the island with xxmaj europe rather than with xxmaj asia , so this was the reason for sorting the stub templates the way i did . xxmaj originally , we just used for all articles , but the material became so big that we broke it up by continent . i suspect that a stub template for xxmaj middle xxmaj east politicians will eventually</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>: xxunk \\n  i have tagged xxmaj image : xxunk as , because it does not provide a fair use rationale . xxmaj if you believe the image to be acceptable for fair use according to xxmaj wikipedia policy , please provide a rationale explaining as much , in accordance with the fair use rationale guideline , on the image description page . xxmaj please also consider using or</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 49:10 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.073876</th>\n",
       "    <th>3.899197</th>\n",
       "    <th>0.324654</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_lm_fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb97c8ec400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb97c8ec400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])\n",
       "bptt: 70\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('toxic_lm_fit_head')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restart kernel due to memory errors.. reload the learn object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48\n",
    "\n",
    "data_lm = TextLMDataBunch.load(path,'toxic_lm',bs=bs)\n",
    "\n",
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f017ad66620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f017ad66620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])\n",
       "bptt: 70\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('toxic_lm_fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 4:30:11 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.753279</th>\n",
       "    <th>3.635272</th>\n",
       "    <th>0.357043</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.583140</th>\n",
       "    <th>3.549110</th>\n",
       "    <th>0.370405</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.497261</th>\n",
       "    <th>3.484976</th>\n",
       "    <th>0.379287</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>3.414970</th>\n",
       "    <th>3.444479</th>\n",
       "    <th>0.384658</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.380303</th>\n",
       "    <th>3.435067</th>\n",
       "    <th>0.385540</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_lm_fit_head_finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After overnight run, save and keep training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYXHWd7/H3t/d9S3fWTtJZgBASyAayKLIZFpkoysygw1wdncHrjAvi8lzH+6DidZ9xGXXuiFz3UUdQHARCACEqIQsJIUlnI/vae6fXdFcv9b1/VKVtm+6kk/Spqq76vJ6nHqpO/arO90d16lPnd875HXN3REREANLiXYCIiCQOhYKIiAxQKIiIyACFgoiIDFAoiIjIAIWCiIgMUCiIiMgAhYKIiAxQKIiIyICMeBdwtsrLy72qqireZYiIjCubNm1qdPeKM7ULPBTMLB3YCBxz99tHaHMn8DBwubtvPN37VVVVsXHjaZuIiMgQZnZoNO1iMXz0YWDnSE+aWSHwIWB9DGoREZHTCDQUzKwSeDPw0GmafQ74CtAdZC0iInJmQW8pfAP4BBAe7kkzWwxMd/fHA65DRERGIbBQMLPbgXp33zTC82nA14GPjuK97jGzjWa2saGhYYwrFRGRU4LcUrgGWGFmB4FfADeY2U8HPV8ILABWR9tcCTxmZsuGvpG7P+juy9x9WUXFGXeei4jIOQosFNz9k+5e6e5VwF3Ac+5+96DnW9293N2rom3WASvOdPSRiIgEJ+Ynr5nZA2a2ItbrFRGRM4vJyWvuvhpYHb1//whtrotFLSIi40047Hxx5U7esmgaC6YVB7ouTXMhIpLgthxt4Xt/PMCe+vbA16VQEBFJcKu215GRZtxw0aTA16VQEBFJYO7Oqu21XDVnAsV5mYGvT6EgIpLA9tR3cKCxk+WXTI7J+hQKIiIJbFV1LQDL5wc/dAQKBRGRhLZqRy2LZ5QwqSgnJutTKIiIJKijJ05SfayNm2M0dAQKBRGRhPX09joAhYKIiMCq7bVcNKmQWeX5MVunQkFEJAE1dYR46WAzN18Smx3MpygUREQS0O921hN2YnYo6ikKBRGRBPTU9lqmleRyydSimK5XoSAikmA6Qn28sKeRmy+ZjJnFdN0KBRGRBLN6dz09/eGY708AhYKISMJ5clsN5QXZLKsqi/m6FQoiIgmkM9THc7vquW3hZNLTYjt0BAoFEZGE8uzOOrp7w9x+6dS4rF+hICKSQJ7YWsOkomyWzSyNy/oVCiIiCaK9u5fVrzZw28IppMVh6AgUCiIiCePZnXX09MVv6AgUCiIiCePxLTVMLc5h8fSSuNWgUBARSQCtJ3v5w54G3nxp/IaOQKEgIpIQnt5RS2+/x3XoCBQKIiIJ4fGtNUwvy+XSyuK41qFQEBGJsxOdPazZ28ibF06N+VxHQykURETibNX2WvrCzu2XTol3KQoFEZF4e2JbDbPK82M+TfZwFAoiInF0orOHF/c1ceuC2E+TPRyFgohIHD2zs47+sHPrgvgPHYFCQUQkrp6qrqWyNJcF0+I/dAQKBRGRuGnv7uWFPY3cEocrrI1EoSAiEifP7YpcYe3WhZPjXcqAwEPBzNLNbLOZPT7Mc/eZ2Q4z22pmvzOzmUHXIyKSKFZuq2ViYTaLp8dnmuzhxGJL4cPAzhGe2wwsc/dLgUeAr8SgHhGRuOvq6Wf1q/XcfMnkuM51NFSgoWBmlcCbgYeGe97dn3f3k9GH64DKIOsREUkUv3+1nu7eMLcuSJyhIwh+S+EbwCeA8CjavhdYOdwTZnaPmW00s40NDQ1jWZ+ISFysrK6lNC+TK2aVxbuUPxNYKJjZ7UC9u28aRdu7gWXAV4d73t0fdPdl7r6soqJijCsVEYmtUF8/z+2sZ/n8yWSkJ9bxPhkBvvc1wAozuw3IAYrM7KfufvfgRmZ2E/Ap4I3uHgqwHhGRhLBmbyPtoT5uSaCjjk4JLKLc/ZPuXunuVcBdwHPDBMJi4LvACnevD6oWEZFEsnJbLYXZGVw9Z0K8S3mNmG+3mNkDZrYi+vCrQAHwsJm9YmaPxboeEZFY6u0P88zOOm68eCLZGenxLuc1ghw+GuDuq4HV0fv3D1p+UyzWLyKSKNbvb6blZC+3JMhcR0Ml1h4OEZEk92R1DXlZ6Vx3UWIeNKNQEBGJkf6ws6q6luvnTSQnM/GGjkChICISMxsONNPU2cNtCTp0BAoFEZGYWVldQ05mWsIOHYFCQUQkJsJhZ2V1LdddOJH87Jgc43NOFAoiIjGw6fAJGtpDCTVN9nAUCiIiMfDkthqyMtK4Yd7EeJdyWgoFEZGAhcPOU9W1XHtBBYU5mfEu57QUCiIiAXvlaAs1rd3cluBDR6BQEBEJ3MptNWSmGzdePCnepZyRQkFEJEDuzpPbann93HKKcxN76AgUCiIigdp2rJVjLV3cujBxT1gbTKEgIhKgJ7fVkpFmLJ+f+ENHoFAQEQmMu/NUdQ1XzZlASV5WvMsZFYWCiEhAdta0c7DpJLeNk6EjUCiIiARmZXUNaca4GToChYKISCDcnSe21XDl7AlMKMiOdzmjplAQEQnAnvoO9jd0jpujjk5RKIiIBODJbTWYwc2XjJ+hI1AoiIgEYuW2Wi6vKmNiYU68SzkrCgURkTG2t76D3XXt3LYg8ec6GkqhICIyxp6qrgHglgS+7OZIFAoiImPsyW21LJlRwuTi8TV0BAoFEZExdbCxkx01bePqhLXBFAoiImNoZXUtALeMw/0JoFAQERlTK6truLSymMrSvHiXck4UCiIiY6SmtYutR1vH7VYCKBRERMbMszvqAFg+X6EgIpLynt5Rx+yKfOZOLIh3KedMoSAiMgZau3pZu69pXG8lgEJBRGRMrN5dT1/YedM4miZ7OIGHgpmlm9lmM3t8mOeyzey/zGyvma03s6qg6xERCcLT2+soL8hm8fSSeJdyXmKxpfBhYOcIz70XOOHuc4GvA1+OQT0iImMq1NfP6t31vGn+JNLSLN7lnJdAQ8HMKoE3Aw+N0OQtwI+i9x8BbjSz8f1/VERSzov7mujs6Wf5OJsmezhBbyl8A/gEEB7h+WnAEQB37wNagQkB1yQiMqae3l5HflY6V88Z/19fgYWCmd0O1Lv7ptM1G2aZD/Ne95jZRjPb2NDQMGY1ioicr3DYeWZHHdfNm0h2Rnq8yzlvQW4pXAOsMLODwC+AG8zsp0PaHAWmA5hZBlAMNA99I3d/0N2XufuyioqKAEsWETk7m4+00NgRYvk4P+rolMBCwd0/6e6V7l4F3AU85+53D2n2GPCu6P07o21es6UgIpKont5RS2a6cf28ifEuZUxkxHqFZvYAsNHdHwP+H/ATM9tLZAvhrljXIyJyrtydp7fXceXsCRTlZMa7nDERk1Bw99XA6uj9+wct7wb+MhY1iIiMtf2NnRxo7OTvrqmKdyljRmc0i4icoz++Gjnw5fqLkmPoCBQKIiLn7IW9Tcwoy2N62fi8dsJwFAoiIuegrz/Muv1NvP6C8niXMqYUCiIi52DL0RY6Qn28fq5CQUQk5b2wpwkzuGr2+D+LeTCFgojIOVizt5GF04opzc+KdyljSqEgInKWOkJ9vHz4BNck2dARKBRERM7ahgNN9IU96fYngEJBROSsvbCnieyMNJbOLI13KWNuVKFgZnPMLDt6/zoz+5CZje/LC4mInKMX9jZwxawycjLH/6yoQ412S+FXQL+ZzSUyX9Es4GeBVSUikqDq27p5ta4jKfcnwOhDIRy9CM4dwDfc/SPAlODKEhFJTGv2NQIk5f4EGH0o9JrZO4hMc/14dFlyTAkoInIWXtjTRGleJvOnFMW7lECMNhT+DrgK+Ly7HzCzWcDQC+aIiCQ1d+eFvQ1cPbectLTkvJz8qKbOdvcdwIcAzKwUKHT3LwVZmIhIotnX0EFdW4g3JOnQEYz+6KPVZlZkZmXAFuAHZva1YEsTEUksL+yJ7E9I1p3MMPrho2J3bwPeBvzA3ZcCNwVXlohI4knGqbKHGm0oZJjZFOCv+NOOZhGRlNHXH2b9/qak3kqA0YfCA8AqYJ+7v2Rms4E9wZUlIpJYth5rpT0Jp8oearQ7mh8GHh70eD/w9qCKEhFJNGui+xOumpNcU2UPNdodzZVm9qiZ1ZtZnZn9yswqgy5ORCRRrNnXyCVTiyhLsqmyhxrt8NEPgMeAqcA04LfRZSIiSe9kTx8vH2pJ+v0JMPpQqHD3H7h7X/T2Q6AiwLpERBLGSwdP0NMfVigM0mhmd5tZevR2N9AUZGEiIonixb2NZKWncXlV8k2VPdRoQ+E9RA5HrQVqgDuJTH0hIpL0XtjbyOIZJeRljerYnHFtVKHg7ofdfYW7V7j7RHd/K5ET2UREklpzZw87atqS/lDUU87nymv3jVkVIiIJau2+JtzhaoXCGSXnFIEiIoOs2ddIQXYGl1UWx7uUmDifUPAxq0JEJEGt2dvIlbPLyEhPjUvan3aviZm1M/yXvwG5gVQkIpIgjjSf5FDTSd59dVW8S4mZ04aCuxfGqhARkUTz4r7knyp7qMC2h8wsx8w2mNkWM9tuZp8dps0MM3vezDab2VYzuy2oekREztaavU1UFGZzwcSCeJcSM0EOkoWAG9z9MmARcIuZXTmkzf8Gfunui4G7gH8PsB4RkVFzd17c18g1cyZgljrH1QR2Joa7O9ARfZgZvQ3dP+HAqatfFwPHg6pHRORs7K3voLGjJ+lnRR0q0N3p0SkxXgHqgWfcff2QJp8B7jazo8CTwAeDrEdEZLTW7Y/M5HPV7NTZnwABh4K797v7IqASuMLMFgxp8g7gh+5eCdwG/MTMXlOTmd1jZhvNbGNDQ0OQJYuIALB2fxNTi3OYXpZaB1rG5MBbd28BVgO3DHnqvcAvo23WAjnAa2LZ3R9092XuvqyiQpOzikiwwmFn3f5mrkyx/QkQ7NFHFWZWEr2fC9wE7BrS7DBwY7TNxURCQZsCIhJXe+o7aO7s4crZqbU/AQLc0QxMAX5kZulEwueX7v64mT0AbHT3x4CPAt8zs48Q2en87ugOahGRuFkbPT/hKoXC2HH3rcDiYZbfP+j+DuCaoGoQETkX6/Y3M60kl+llefEuJeZSYzIPEZFRCoeddQeaUu5Q1FMUCiIig+yua6flZG9K7k8AhYKIyJ9Zuy96foK2FEREZN3+JmaU5TGtJLXOTzhFoSAiEhUOO+sPNHPl7LJ4lxI3CgURkagdNW20dvWm7NARKBRERAacmu8oVXcyg0JBRGTAuv1NVE3IY0pxau5PAIWCiAgA/QP7E1J3KwEUCiIiAOysaaO9u0+hEO8CREQSwaZDJwBYVlUa50riS6EgIgJsPnyCiYXZKXt+wikKBRER4OXDLSyZUZpy108YSqEgIimvsSPE4eaTLJ5REu9S4k6hICIpb/PhFgCWzEzt/QmgUBAR4eXDJ8hIMxZOK453KXGnUBCRlLf58AnmTy0iJzM93qXEnUJBRFJaX3+YLUdaWTJDQ0egUBCRFLe7rp2u3n7tZI5SKIhISnv51E5mbSkACgURSXGbD52gvCCLytLUPmntFIWCiKS0zUdaWKyT1gYoFEQkZTV39nCgsVNDR4MoFEQkZb1yJDIJnnYy/4lCQURS1suHWkhPMy6t1ElrpygURCRlvXz4BPMmF5KXlRHvUhKGQkFEUlJ/2NlypEX7E4ZQKIhISnq1rp3Onn6WzNT+hMEUCiKSkk7NjLp4urYUBlMoiEhKenFfI+UFWcyckBfvUhKKQkFEUk53bz/P76rnTfMn66S1IRQKIpJy/vBqA509/dy2cHK8S0k4gYWCmeWY2QYz22Jm283ssyO0+ysz2xFt87Og6hEROWVldS0leZlcOXtCvEtJOEEenBsCbnD3DjPLBF4ws5Xuvu5UAzO7APgkcI27nzCziQHWIyJCqK+fZ3fUcevCyWSma7BkqMBCwd0d6Ig+zIzefEizfwC+4+4noq+pD6oeERGANXsbaQ/1ceuCKfEuJSEFGpNmlm5mrwD1wDPuvn5IkwuBC81sjZmtM7NbRnife8xso5ltbGhoCLJkEUlyT26rpTAng6vnauhoOIGGgrv3u/sioBK4wswWDGmSAVwAXAe8A3jIzF5zJom7P+juy9x9WUVFRZAli0gS6+kL8/T2Wt508SSyM3Q95uHEZEDN3VuA1cDQLYGjwH+7e6+7HwB2EwkJEZExt3Z/E23dfdy6UENHIwny6KOKU7/6zSwXuAnYNaTZb4Dro23KiQwn7Q+qJhFJbU9V15Cflc4bLiiPdykJK8ijj6YAPzKzdCLh80t3f9zMHgA2uvtjwCpguZntAPqBj7t7U4A1iUiK6usPs2p7HTdePImcTA0djSTIo4+2AouHWX7/oPsO3Be9iYgEZsOBZpo7e3TC2hnoIF0RSQlPVteQm5nOGy/U6VCno1AQkaTX1x/mqeo6rp9XQW6Who5OR6EgIknvhb2NNHaEWHHZtHiXkvAUCiKS9H798jGKczO5fp7OczoThYKIJLWOUB9P76jl9kun6IS1UVAoiEhSW7mthu7eMG9boqGj0VAoiEhSe3TzMWZOyGPJDF12czRSMhSaOkKs3l3PQ3/cT/Wx1niXIyIBqWntYu3+Jt66aJqusDZKQZ7RnFCe31XPzzccpvpYK8dbu//suWUzS3nX1VXcskDzq48Fd6e5s4eSvCzS0/QPUeLnN5uP446Gjs5CyoRCbVs3e+o7WFpVxrunFbFwWgkzJ+SxsrqWH689yAd/vplJRdncfulUFk0vYdH0EipLc/Xr4gz6+sOcONnL4eaTbD58gk2HIrf69hA5mWlcNLmI+VOKmD+1iILsdJo6ejhxsofmzh5yMtP5wPVzmVCQHe9uSBJydx7dfJSlM0uZOSE/3uWMGxaZaWL8WLZsmW/cuPGsX+fuI37Bh8PO6lfr+fHaQ6zd10SoLwxAWX4W8yYXUpSTSV52OvlZGRTmZPD2pZXMqSg4r36MB109/bxypIWtR1to6uzhRGcPJ0720trVQ1Nn5Iu9tauXwX9C08tyWTqjlEumFlPb1s2O423sqGmjtat3oE16mlGal0lrVy/FuZl84Y6FLL9EUw/I2Ko+1srt33qB//PWBdx95cx4lxN3ZrbJ3ZedqV3KbCmc7hd/Wppxw7xJ3DBvEr39YXbXtrPlaAtbjrSwp76Dxo4QnaF+Tvb00d7dxw9fPMgDb1nAnUsrY9iD4PWHnXX7m3huVz0bD51g+7FW+sKRb/yczDRKcrMoycukJC+TeZMLKcvPoiw/mwn5WUwuzmHx9BImFuW85n3dneOt3YR6+5mQn01hTgZpacbu2nY+8l+vcM9PNnHn0kru/4v5FOVkxrrbkqQe3XyMrPQ0br9U02SfjZTZUhgrta3dfPgXm1l/oJm3LZ7GA29dQEF24mSru9PY0UNNaxfHW7pp6gzR1dPPyZ5+unr76e0LM7Ukl1kV+cwuz2daSS47a9r5zSvH+O2W49S3h8jOSOOyyhKWVpVyeVUpi6eXUpqfFUi9PX1hvvXcHr7z/F6mFOfy9b9exBWzygJZl6SOvv4wV37xOZbOLOG7f3vGH8cpQVsKAZlcnMPP/uFKvv3cXr75u1fZfKSFz6y4hGUzS8kfIRy6e/sDn6q3+lgrn35sO9uOtdITHf4aKjPdSDMbGB4DSDMIe+S56y6ayFsXTePGiyfGbGrhrIw0Prr8Im6YN5H7frmFux5cy0eXX8T73ziHNO2klnP0zI46GjtC3LE4ubbmY0FbCudh3f4m7v3FK9S2dZNmcOGkQi6rLKGqPJ8jJ06yr76DfQ2dNHaEeMMF5Xz57ZcytSR3TGvo6Qvz7ef28O+r91Gan8Udi6cxrSSXKcU5TC3Jpbwgm7zsdHIz08lMT8Pdaers4UBjJwcaOjnY1Mn0sjxuWzCF4rz4Dt10hPr4519v47Etx3nDBeV8/a8XUa6d0HKW+vrDLP/GHzBg1b3XkqEjCoHRbykoFM5TR6iPDQeaeOVIK1uOtLDlaAstJ3spyctkTkUBcyryKcnL4idrD5GRZtz/F/O5c2nlmBzVtO1oKx9/ZAu7att525Jp3H/7fEryghnmiRV35xcvHeHTj22nJDeTb79ziYaT5Kz8fMNhPvnrbXz3b5dysw5gGKBQiBN3pyPUR+GQHaaHmjr5+MNb2XCwmRvnTeSf33wxlaW5ZzUXS3dvPxsPnuDFfY2s2dfEtqMtVBRm84U7FnLjxZPGuitxteN4Gx/42cscPdHF1/96EW/WzkIZha6eft741eepLM3lV++/WoeUD6JQSEDhsPODFw/ylad2DYzrl+RlUlGQzaSiHKaV5DKtNJfK0lymFOfScrKHfQ2RIah9DR3sqmmnpz9MRppx2fQSXj+3nPdcMyvuwz5BaT3Zy3t/9BKbDp/gsysu4X9cVRXvkiTBfef5vXx11W5++b6rtIU5hEIhgR1uOsmL+xppaA9R3x6ioT1EbVs3x1u6qG8Pvab91OIc5kwsYN7kQq6eU87ls8oS6oinIHX39vOBn23m2Z11fPCGudz3pgv160+GdaKzh2u/8jyvm13GQ++6PN7lJBwdfZTAZkzIY8aEGcM+193bT01rJCCKczOZXZFPXlbqfkw5men8x91L+NSj1Xzrub3Ut4X47Fsu0YXX5TW+8/xeOnv6+PjN8+JdyriWut82CSonM51Z5fnMKtdp+adkpKfxpbcvpKIwm28/v5f1B5r4wtsWcvWc8niXJgni6ImT/HjtId6+pJKLJhfGu5xxTcdqybhgZnzs5ov46XtfR9jhnd9bz//61VZaT/ae+cWS1Nydzz+xEww+8qYL413OuKdQkHHl9ReUs+rea3nfG2fz8Kaj3Pi13/PjtQc52dMX79IkTn7zyjFWVtdy700XjPl5QKlIoSDjTm5WOp+89WL++5+uYeaEPO7/7+1c/aXn+JdVu6lv7z7zG0jSONbSxf2/2c7lVaW879o58S4nKejoIxnX3J1Nh07wvT/u5+kddWSmpXHDvIlcPquMpTNLmT+liKwM/fZJRuGw886H1rHtaCtP3Xst08vy4l1SQtPRR5ISzIxlVWUsqyrjYGMnP1hzgN/tquep7bUAZGeksWRGKXcsmcbtl05J6SO5ks331xxg3f5mvnLnpQqEMaQtBUlKdW3dAxf8eX53PfsbOinIzmDFoqncdfl0Fk4r1vkO49iu2jZWfGsN111UwXf/dqk+y1HQyWsiUaeGmH6+4QhPbDtOd2+YGWV5XH9RBdfNm8hVsyfovIdx5GBjJ3//4420nOxh1b3X6sp9o6RQEBlGW3cvj2+p4Xc761izr5Hu3jDZGWlcMauMxTNKWTyjhMXTS8b9xILJyN15ZNNRPvPYdtLTjP+4eylXz9W5KqOlUBA5g+7eftYfaOb5XfWsP9DM7to2ohea44KJBfz9G2bx9iWVmno5AbSe7OWfH93GE9tquHJ2GV/7q0U6/PQsKRREzlJnqI+tR1vZfOQET1XXsvVoK7PK87n3pgv4i0un6qI/cVDT2sXjW2r4/poDNLSHuG/5hbzv2jmk67M4a3EPBTPLAf4AZBM5yukRd//0CG3vBB4GLnf3037jKxQkFtydZ3bU8bVnXmVXbTvzJhfyj9fP5dYFk8nUlsOIunv7yUiz89q6qmvr5tmddTz2ynE2HGzGHS6bXsIDKy7hsuklY1htakmEUDAg3907zCwTeAH4sLuvG9KuEHgCyAI+oFCQRBIOO7/depxvPruH/Y2dTCzM5m9eN5N3vm4GFYXjewenuxPqC9MR6uNkqJ/Wrl5q27qpae2iprWbhvYQcyoKeN3sMhZOKx42DNu6e3npQDPr9jexdn8T24+3YcCEgmwmFkamhM/NSqenL0xvf5ievjDuMKkomykluUwtzmFiUQ6Hm06y+cgJNh9uoaY1cgLinIp8Vlw2jRWLpmousDEQ91AYUkwekVB4v7uvH/LcN4BngY8BH1MoSCIKh53fv9rAD188yO9fbSArPY2r505gWkkuk4pymFSUzcTCHApyMsjLSic/K4O87HQm5GfHbaiju7efdfub+P2rDazf30x7qJdQb5ie6Jdzd2//wD6UoTLSjNL8LBqiU7nnZqazdGYpFYXZNHZEpntv7AjR1NmDe+Ra20tmlHBFVeQaBnVtIerbu6lrC9Hd209WRlrklp6GE9kaqG3tpm9QAdPLclk0vZTF00u4cvYELp5SqENNx1BCnLxmZunAJmAu8J1hAmExMN3dHzezjwVZi8j5SEszrp83kevnTWRfQwc/WXuIdfub2Hq0lebOnhFfl5eVzsVTilgwtYhLphVTUZhNXWs3x1u7qWnporEjREFOJmV5mZTmZzEhP4uy/GwmFGRRXpBFeUE2RTmZr9mf4e60dfVxrKWLmtYumjp6aOvupbWrl7auXvY3drLhQDOhvsjRVZdXlTFvcuGffTnnZqWTl5VBfnbkv4U5GUwpzmFycQ7l+dmkpRmNHSFeOtDM+gPNbDjQzMGmTsoLsplelsfiGaVMLc5hWVUZi2eUnPVhvf1hp7EjRG1rN1NLcsf9lleyiNWWQgnwKPBBd6+OLksDngPe7e4HzWw1I2wpmNk9wD0AM2bMWHro0KHAaxYZrVBfP/VtIRo6QnSG+ugM9XOyp4+OUB/7GzrZfryVHcfb6OzpH3iNGUwszKa8IJuTPf00d/bQ2jXyjK+5menkZqWTm5lOZrrR0B76s/cb/L5FOZlMLsrhmrnlvPGiCl43q0znYUhiDR8BmNmngU53/5fo42JgH9ARbTIZaAZWnG4IScNHMh6Fw87Bpk6aO3uYXJzDpKKc14zR9/WHOXGyl+bOHpo6IiHT1NFDS1cv3b39dPX009XbT6gvTEVBNlNLcphaksuU4hwqCrMpys2kICtDR0nJsOI+fGRmFUCvu7eYWS5wE/DlU8+7eytQPqj9akaxT0FkPEpLM2ZXFDC7YuQ2GelpVBRmR4dRdKEYiY8gj62bAjxvZluBl4BnovsOHjCzFQGuV0REzlFgWwruvhVYPMzy+0dof11QtYiIyOjoLBwRERmgUBARkQEKBRERGaBQEBGRAQoFEREZoFCUoJSVAAAHeklEQVQQEZEB4+56CmbWAAyd56IYaD3DstM9Hu5+OdB4nuUOV9fZtAmiX3D+fQuiX8MtH6n+wY9j3a8ztUvlv8Why/S3eO6C+Fuc6e6nOX0yyt3H/Q148EzLTvd4uPvAxiDqOps2QfRrLPoWRL/Opi9DPqeY9isen9l4+VscTV/i8Znpb/HsbskyfPTbUSw73eOR7p+v0bzX6dqkUr+GW366+n87wvLzMdr30mc2umXjtV/DLU+Wv8UzGnfDR7FiZht9FJNHjUfJ2jf1a/xJ1r6N534ly5ZCEB6MdwEBSta+qV/jT7L2bdz2S1sKIiIyQFsKIiIyICVCwcy+b2b1ZlZ9Dq9dambbzGyvmf2bDbporJl90Mx2m9l2M/vK2FY9qtrGvF9m9hkzO2Zmr0Rvt4195aOqL5DPLPr8x8zMzax8pPcISkCf2efMbGv083razKaOfeVnrC2Ifn3VzHZF+/Zo9AqOMRdQ3/4y+r0RNrPE2vdwPodNjZcbcC2wBKg+h9duAK4CDFgJ3Bpdfj3wLJAdfTwxSfr1GSIXO0q6zyz63HRgFZFzXcqToV9A0aA2HwL+I0n6tRzIiN7/MvDlZPlbBC4GLgJWA8vi0a+RbimxpeDufyByqc8BZjbHzJ4ys01m9kczmzf0dWY2hcg/uLUe+SR/DLw1+vT7gS+5eyi6jvpge/FaAfUrIQTYt68DnwDisjMtiH65e9ugpvnEoW8B9etpd++LNl0HVAbbi+EF1Led7r47FvWfrZQIhRE8CHzQ3ZcCHwP+fZg204Cjgx4fjS4DuBB4g5mtN7Pfm9nlgVY7eufbL4APRDfZv29mpcGVetbOq28WueLfMXffEnShZ+m8PzMz+7yZHQH+Bhj2QlZxMBZ/i6e8h8gv7UQxln1LKIFdeS2RmVkBcDXw8KDh5uzhmg6z7NSvsAygFLgSuBz4pZnNjv4iiIsx6tf/BT4Xffw54F+J/IOMq/Ptm5nlAZ8iMiSRMMboM8PdPwV8ysw+CXwA+PQYl3pWxqpf0ff6FNAH/OdY1niuxrJviSglQ4HIFlKLuy8avNDM0oFN0YePEfmCHLzJWgkcj94/Cvw6GgIbzCxMZL6ThiALP4Pz7pe71w163feAx4Ms+Cycb9/mALOALdF/yJXAy2Z2hbvXBlz76YzF3+JgPwOeIM6hwBj1y8zeBdwO3BjPH1xDjPVnlljivVMjVjegikE7ioAXgb+M3jfgshFe9xKRrYFTO4puiy7/n8AD0fsXAkeInvcxzvs1ZVCbjwC/SJbPbEibg8RhR3NAn9kFg9p8EHgkSfp1C7ADqIjX32DQf4sk4I7muBcQow/050AN0EvkF/57ifxqfArYEv3Du3+E1y4DqoF9wLdPffEDWcBPo8+9DNyQJP36CbAN2Erk186UWPUn6L4NaROXUAjoM/tVdPlWIvPdTEuSfu0l8mPrlegt5kdVBdi3O6LvFQLqgFXx6NtwN53RLCIiA1L56CMRERlCoSAiIgMUCiIiMkChICIiAxQKIiIyQKEg456ZdcR4fQ+Z2fwxeq/+6Oym1Wb22zPNBGpmJWb2j2OxbpHh6JBUGffMrMPdC8bw/TL8TxOxBWpw7Wb2I+BVd//8adpXAY+7+4JY1CepR1sKkpTMrMLMfmVmL0Vv10SXX2FmL5rZ5uh/L4ouf7eZPWxmvwWeNrPrzGy1mT0SndP/PwfNhb/61Bz4ZtYRnYxui5mtM7NJ0eVzoo9fMrMHRrk1s5Y/Td5XYGa/M7OXLTIf/1uibb4EzIluXXw12vbj0fVsNbPPjuH/RklBCgVJVt8Evu7ulwNvBx6KLt8FXOvui4nMJvqFQa+5CniXu98QfbwYuBeYD8wGrhlmPfnAOne/DPgD8A+D1v/N6PrPON9NdN6cG4mcRQ7QDdzh7kuIXLvjX6Oh9L+Afe6+yN0/bmbLgQuAK4BFwFIzu/ZM6xMZSapOiCfJ7yZg/qBZLIvMrBAoBn5kZhcQmbEyc9BrnnH3wfPmb3D3owBm9gqR+W9eGLKeHv40aeAm4E3R+1fxp+s4/Az4lxHqzB303puAZ6LLDfhC9As+TGQLYtIwr18evW2OPi4gEhJ/GGF9IqelUJBklQZc5e5dgxea2beA5939juj4/OpBT3cOeY/QoPv9DP/vpdf/tGNupDan0+Xui8ysmEi4/BPwb0Sui1ABLHX3XjM7COQM83oDvuju3z3L9YoMS8NHkqyeJnJdAQDM7NQ0x8XAsej9dwe4/nVEhq0A7jpTY3dvJXIpzY+ZWSaROuujgXA9MDPatB0oHPTSVcB7onP8Y2bTzGziGPVBUpBCQZJBnpkdHXS7j8gX7LLoztcdRKY6B/gK8EUzWwOkB1jTvcB9ZrYBmAK0nukF7r6ZyKybdxG5oMwyM9tIZKthV7RNE7AmegjrV939aSLDU2vNbBvwCH8eGiJnRYekigQgeqW3Lnd3M7sLeIe7v+VMrxOJN+1TEAnGUuDb0SOGWkiAS5qKjIa2FEREZID2KYiIyACFgoiIDFAoiIjIAIWCiIgMUCiIiMgAhYKIiAz4/8YB/bax91NcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fc7fd31e400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (250187 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (250187 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  = = xxmaj racist = = \n",
       "\n",
       "  xxmaj this video game is n't just \" \" pornographic \" \" it 's racist and depicts xxunk rape . \n",
       "\n",
       "  xxmaj also , the word \" \" xxunk \" \" should be xxunk , and should really be changed to \" \" woman \" \" . \", Text xxbos : xxmaj please do not add nonsense to xxmaj wikipedia . xxmaj it is considered vandalism . xxmaj if you would like to experiment , use the sandbox . xxmaj thank you . -, Text xxbos = = xxmaj on edit warring and xxup pov = = \n",
       "\n",
       "  xxmaj someone pointed out this ' edit war ' on my talk page , and i 've been avoiding it . xxmaj but i took a look today and it seems pretty simple , really . xxmaj in certain areas , urban exploration is lumped with xxunk and breaking and entering , thus making it illegal . xxmaj in other areas , it is , what i suppose amounts to , de facto legal , as nobody is being arrested for it , though there probably are n't laws specifically allowing it . xxmaj so ... say something like that in the article . xxmaj all you need is a couple of sentences , with a few citations , that says exactly what i just said . xxmaj some areas consider it illegal and lump it together with xxrep 4 . xxmaj other areas do n't have any laws xxrep 4 . xxmaj really , of all the edit wars we have going on in the project , this one is pretty weak - ass . xxmaj work out the differences here and i 'll be more than happy to lift the protection and we can all move on . xxmaj cheers ., Text xxbos = = xxunk = = \n",
       "\n",
       "  i do n't know if anyone is interested in adding more examples , but i know xxup 3d - drafting software xxunk has a xxunk - like interface as of the 2009 version ., Text xxbos xxmaj how about you block me from editing everything , with the exception of this page .]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (48861 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/toxic\n",
       "x: LMTextList (48861 items)\n",
       "[Text xxbos \" \n",
       "\n",
       "  i 'm going to have to pick up the xxunk instead and hand it over to you , xxmaj george . xxmaj if this was a personal friend of yours you have no business editing the article as there is a conflict of interest which should have been fully disclosed from the get go . i 'm disappointed . ( ( talk ) ✄ ✄ ✄ xxup tab \", Text xxbos \" : : xxmaj crum375 : what complete rubbish : xxmaj why the hell should i do what anyone with a mouse and the ability to click on the history page can do ? xxmaj for someone who ca n't be bothered reading my contributions .. xxmaj that request was completely and utterly out of line and just another diversion from ever answering a straight question . xxmaj how about you lot adhering to the dispute avoidance policy which states xxup not xxup to xxup revert others work , and that there are more constructive additions . \n",
       "  : : xxmaj but let 's look at some diffs then ( since i guess that big often hit revert button must be getting in the way ) : this one showing xxup sv reverting my addition of a referenced definition , an addition , another one , one that was the result of the discussion and consultation of others , more of the consensus editing , to fit the policy on international english terms ( and a bunch of other edits ) , more accurate sourced lead ( reverted by xxup sv ) . xxmaj in fact all this was able to be found in the first few pages of the history .. xxmaj would you like me to explain how to use a mouse to drive a web application or can you do this for yourselves on any of the related pages ( e.g. intensive farming that i supposedly never contribute to ) since that part of your pointless request is still \" \" outstanding \" \" and i have no intention of wasting further time on doing what you yourselves can ( and should ) do . xxmaj perhaps i need to do more constructive edits ( labelled \" \" minor \" \" ) like this one eh ? \n",
       "\n",
       "  \", Text xxbos * i took this image of xxmaj st. xxmaj moritz from xxmaj xxunk da xxmaj xxunk , i think it might a good candidate to give the reader a better perspective of how xxmaj st. xxmaj moritz really looks like and its surroundings . i would substitute one of the current images with this one , but of course i am the author of this picture , so i want to validate your opinions first . xxmaj check it out here : \n",
       "  :, Text xxbos i agree . xxmaj once an xxup ip has been tainted , i do n't see the logical possibility of assuming anything other than suspicion ., Text xxbos \" \n",
       "  xxmaj um ... \n",
       " xxmaj sir / xxmaj madame , \n",
       "\n",
       " i am not simply creating a clan . xxmaj it is what it is ! i am in talks with the xxmaj lord xxmaj lyon xxmaj king of xxmaj arms currently about having my clan recognized as an \" \" official \" \" clan of xxmaj scotland . xxmaj his ( the xxmaj uk 's government ) definition of clan is this : xxup any family which is comprised of members who claim the same ancestry ! xxmaj as mine does , i will keep undoing your and others ' habitual xxunk of my entry for my xxup clan ! xxmaj thanks . \n",
       "\n",
       " \"]...\n",
       "Path: /data/toxic;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fc7fd31e400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/toxic'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])\n",
       "bptt: 70\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('toxic_lm_fit_head_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 4:00:10 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.323418</th>\n",
       "    <th>3.435407</th>\n",
       "    <th>0.385552</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.300102</th>\n",
       "    <th>3.436674</th>\n",
       "    <th>0.385592</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.343982</th>\n",
       "    <th>3.437548</th>\n",
       "    <th>0.385712</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>3.301852</th>\n",
       "    <th>3.438042</th>\n",
       "    <th>0.385734</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.362690</th>\n",
       "    <th>3.438035</th>\n",
       "    <th>0.385740</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-4, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('toxic_lm_fit_head_finetuned2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (22500 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/imdb\n",
       "x: LMTextList (22500 items)\n",
       "[Text xxbos xxmaj there really are no redeeming factors about this show . xxmaj to put it simply , its just terrible . xxmaj absolutely dreadful . xxmaj it 's just a dreadful \" reality \" show . xxmaj not only that , it 's dreadful fiction . \n",
       "\n",
       " xxmaj imagine this : a bunch of overly - imaginative teenagers get together one night and go \" xxmaj hey ! xxmaj let 's make a paranormal show just like \" xxmaj ghost xxmaj hunters \" and whatnot ! \" xxmaj so they grab a camera , harass local residents and film random landscapes behind a painfully \" trying - to - be - dramatic - yet - failing - xxunk \" monologue . xxmaj this show is basically a bunch of teenagers running around with a home movie camera trying to make a really bad horror documentary . xxmaj the only difference is this show actually has a budget and writers . a wasted budget and terrible writers . \n",
       "\n",
       " xxmaj oh , the problems , how do i count thee ? xxmaj well , first off , let 's talk about this from a personal level . i am not a total skeptic when it comes to the paranormal . i am willing to believe in what s paranormal and what s not , and i 'm sure there are a lot of people who feel the same . xxmaj so , if you 're going to do a show about the paranormal , you have to do a good job convincing the viewer that what they 're seeing is either paranormal or not , because the viewer can easily believe otherwise . i hate to compare , but i do n't see why not at this point . xxmaj take \" xxmaj ghost xxmaj hunters \" for example . xxmaj in \" xxmaj ghost xxmaj hunters \" you can tell that the cast is leveled with the audience . xxmaj they 're not totally skeptical , yet they 're still willing to keep the possibility of any paranormal anomalies in mind . xxmaj they have to look at something and be willing to say \" this is possible that its simply nothing \" . xxmaj and , with that in mind , they set out to try and prove themselves wrong . xxmaj they use technology and several other gadgets along with constant moderation to determine what is paranormal along with bearing the fact that what they may be monitoring could be nothing in mind . xxmaj not only are they trying to convince themselves what is real and what is not , in the process they are trying to convince you . xxmaj that element of doubt is not present in \" xxmaj paranormal xxmaj state \" . xxmaj strike one . \n",
       "\n",
       " xxmaj in \" xxmaj paranormal xxmaj state \" , the cast simply says \" there 's this spooky place , and its xxup haunted , so we 're going to find some xxup spirits ! \" xxmaj and immediately you know and saying to yourself \" xxmaj okay , convince me otherwise \" . xxmaj the cast is not professional in their interviews . xxmaj in fact , sometimes it seems like they 're just harassing local residents of these so - called \" haunted \" areas . xxmaj they have no real evidence to back up their claims besides assumptions and theories , and the best they can must up is somebody who \" claims \" they can contact the dead , with no one ever backing up who this person is and how valid they really are . xxmaj they could have easily just picked some random person off the street and said \" pretend you can contact spirits for our show \" and went at it . xxmaj in the \" xxmaj xxunk \" episode , this just happens . xxmaj without any convincing evidence towards the end of the show , they bring this sort of individual out where he does a random , painfully scripted \" reading \" of a supposed area of how something is \" haunted \" in order to convince its audience . xxmaj very , very poor effort . i feel that one of the main problems with the show is that it feels scripted . xxmaj during one of the episodes , the cast gets attacked by one of these \" paranormal anomalies \" at times in an attempt to be dramatic . xxmaj these sort of dramatic sequences would make any skeptic laugh and even those who are on the fence realize what they 're watching is just a bunch of tabloid - esquire trash . xxmaj if the show 's aim was to try and convince their audience that these \" paranormal \" events are real , they 're doing a horrifically poor job at doing so . xxmaj strike two . \n",
       "\n",
       " xxmaj however , there is always the counter . xxmaj just one last viewpoint to see if the show is actually worth something . xxmaj what if the show is n't trying to convince you that these paranormal events are real and are simply trying to entertain you with good fiction ? xxmaj it even fails on that level as well . xxmaj if the show 's creators were trying to craft fiction to entertain its audience , the writing is too poor and even on a fictional level , it fails to convince the audience that its cast members are really experiencing the unknown in all its full , horrifying glory . xxmaj the writing is simply not compelling and even , dare i say , boring . xxmaj strike three . \n",
       "\n",
       " xxmaj so what remains of this show is simply a bunch of teenagers who are too willing or too gullible to believe in the paranormal simply because its simply much more amazing than reality who set out with a camera , a bad script and bad actors to generally just make a really bad horror documentary . xxmaj that s all the show is at this point . xxmaj there is no reason to see it , not even for the entertainment factor , and there 's no reason to care about it . xxmaj to be blunt , its lame . xxmaj there are absolutely no redeeming factors about this show ., Text xxbos a moderately interesting start , some pretty scenes in sixteenth - century xxmaj japan , and a promising idea . xxmaj but the execution ? xxmaj the comparison that springs to mind after about fifteen minutes is \" xxmaj cannibal xxmaj women in the xxmaj xxunk xxmaj jungle of xxmaj death . \" xxmaj really . a specialist in \" xxmaj oriental history \" who does n't speak any xxmaj japanese , walks on xxunk without removing her shoes , and is generally dumb as celery ? xxmaj please . xxmaj this looks like a student film : the sets are risible , the acting ( except , perhaps , for the title character ) close to wooden , the plot utterly arbitrary . xxmaj at least \" xxmaj cannibal xxmaj women \" was funny ! xxmaj this is best watched with someone who knows something about xxmaj japan , just to watch disbelief repeatedly crawl across their face ., Text xxbos i kind of like xxup jag . xxmaj it do have it´s charm but lately it´s to much propaganda in it . xxmaj for an outsider ( a non xxmaj american ) the patriotic feeling can be a bit to much . \n",
       "\n",
       " i don´t like that xxmaj rabb and mackenzie goes from being lawyers ( as they were in the early parts of the xxup tv show ) to become super heros that stops wars and rescues entire continents . xxmaj its almost like watching a recruitment video from the xxup us army . \n",
       "\n",
       " i still watch the show , so it´s not that bad . xxmaj but i would prefer more episodes when xxmaj rabb and mackenzie investigates military accidents and don´t save the world in the future ., Text xxbos xxmaj there is a famous short story about a man who becomes the prey of a safari hunter who has lost interest in hunting anything except humans . xxmaj its quite good , and its been done and redone in film and xxup tv many many times . xxmaj some are notable , but this xxunk version , that injects the tired old racism themes , just flat out stinks . xxmaj leguizamo 's slapstick is almost as weak as the unfunny script . xxmaj chaplin , this guy is n't . xxmaj there must be people who find a dwarf who ca nt stop dancing funny , i mean i suppose it is funny in a pathetic freakish way , but its just not enough to carry a movie . xxmaj you have the usual xxmaj nazi xxunk or neo - xxmaj nazi whatever the heck we are supposed to think , type villain , who 's son of course is gay , xxmaj german accents ... get the picture ?, Text xxbos xxmaj this comes close to the worst movie i 've ever seen . xxmaj the writer starts you out in a way that you 'll side with xxmaj jasper ( xxmaj josh xxmaj hartnett ) . xxmaj when he did absolutely nothing wrong , xxmaj sam ( xxmaj leelee xxmaj sobiesky ) leaves him for xxmaj kelley ( xxmaj chris xxmaj klein ) , in a way that leaves you mad at xxmaj sam . xxmaj you are n't let in on what she feels , so her feelings with xxmaj kelley are n't real to you , and their relationship is phony . xxmaj it drags you in either direction , and it gets rather exhausting and annoying . xxmaj the only good thing about this movie that i saw was the cast . \n",
       "\n",
       "]...\n",
       "Path: /data/imdb;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (2500 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/imdb\n",
       "x: LMTextList (2500 items)\n",
       "[Text xxbos xxmaj well , i 'm a huge fan and follower of xxmaj elizabeth xxmaj berkley . i bought this on xxup dvd off of ebay for my boyfriends birthday . xxmaj we sat down to watch it and it was so boring . i do n't remember laughing once . xxmaj it 's only on for about an hour and half and it seemed to take forever to end . xxmaj elizabeth is great in this though . xxmaj maybe it 's just because i 'm a big xxmaj elizabeth xxmaj berkley fan though . xxmaj if she was n't in it i would n't have watched it but every time she came on my face lit up . xxmaj unfortunately even xxmaj elizabeth could n't save this film . xxmaj just the overall story and awful comedy makes this a film you 'd rather miss than waste an hour and a half of your life . xxmaj it 's a very forgetful film ., Text xxbos holy sweet murder this is quite possibly the least funny movie i 've ever seen . you can take my word for this as truth because it 's playing on television right now . it 's really one of the most pathetic productions i 've ever seen . there is not a single redeemable aspect of this flick . it just lacks any humor whatsoever . the only good thing it possibly has going for it is that it 's so unfunny that it 's wholly unmemorable . in fact , i just sat through some ridiculous sub - plot and i ca n't really tell you what went on . the only reason i can even possibly remember having seen this movie is because it 's so absolutely humorless it will stick in my mind forever based on that alone . \n",
       "\n",
       " an absolutely must miss . if your friend wants to show it to you , shoot him and save yourself the boredom ., Text xxbos xxmaj telly xxmaj savalas put on a passable ( but no better than that ) performance as xxmaj xxunk xxmaj villa , the notorious xxmaj mexican bandit / revolutionary in this account of xxmaj villa 's raid on the town of xxmaj columbus , xxmaj new xxmaj mexico in 1916 . xxmaj villa is not really a historical figure who i 'm overly familiar with , so i wo n't say much about the historical details of the film . xxmaj as a movie , this is n't great , although it has a smattering here and there of both action and humour . xxmaj chuck xxmaj connors ' performance as xxmaj colonel xxmaj xxunk , commander of the xxup u.s. xxmaj army base near xxmaj columbus struck me as a bit over the top , and xxmaj clint xxmaj walker as xxmaj villa 's xxmaj xxunk sidekick xxmaj scotty did n't really do very much for me . xxmaj the movie is obviously a pretty low budget effort of limited technical quality . xxmaj for a movie with a runtime of only slightly over an hour and a half i have to say that this movie dragged in places , particularly in the last 20 minutes or so . xxmaj villa 's raid into the xxmaj united xxmaj states was an interesting ( if , in the overall scheme of things , not especially important ) historical xxunk , and probably deserved better treatment than this . 4 / 10, Text xxbos xxup ok , let me start off by saying this is n't a horrible movie by any means . xxmaj it 's just not good . i recall one poster saying the acting is n't campy it 's just nuanced . xxmaj no . i 've seen nuanced xxmaj japanese and xxmaj asian acting . i 'm sorry , you 're wrong . xxmaj this is camp . \n",
       "\n",
       " xxmaj the characters are totally unsympathetic , the deaths are totally random and utterly meaningless . xxmaj the writing is bad . i 'm fine with suspending disbelief , i 'm fine with not having everything handed to me in terms of plot . xxmaj but this movie has no plot . xxmaj one reviewer stated \" xxmaj this movie is set in a small town where people are going nuts over xxunk and spirals . \" xxmaj that 's not a blurb , that 's the entire freaking film . xxmaj congratulations , i 've just saved you nearly an hour and a half . xxmaj there is nothing more to it . xxmaj no character development , no plot development , no explanations , no resolution . xxmaj and not even the \" xxmaj acceptable within the realm of j - xxmaj horror \" lack of resolution . xxmaj just nothing . \n",
       "\n",
       " xxmaj in addition , the musical score is done by someone who obviously was n't actually watching the movie at the time because it 's random enough to cause xxunk . xxmaj xxunk xxunk is one thing and done well it can be brilliant ( see xxmaj dark xxmaj water ) , but here it just seems as if the score was designed to go with another movie all together . \n",
       "\n",
       " xxmaj the best example i can give is it 's as if the xxmaj japanese remade xxmaj evil xxmaj dead without any of the clever bits or good acting . xxmaj it just falls flat . xxmaj it 's j - horror without the horror ., Text xxbos xxmaj boasting the title for the sickest film ever made , xxup pink xxup flamingos is an undisputed classic . xxmaj sure , the camerawork is shaky and off - center , the story is muddled and slow - paced , and every single character in the movie is repugnant and despicable , but xxup pink xxup flamingos has a certain playful charm and brilliant satiric wit that no other movie can match . \n",
       "\n",
       " xxmaj while this film is indeed an offensive one , reading descriptions of what goes on in the movie is much worse than actually seeing it . xxmaj only xxmaj john xxmaj waters can succeed in making rape , murder , sadism , cannibalism , xxunk , and just about every other form of human debauchery known to man seem absolutely hilarious . xxmaj this movie must be seen to be believed .]...\n",
       "Path: /data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(36258, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(36258, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=36258, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb64ebe8620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/imdb'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (22500 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/imdb\n",
       "x: LMTextList (22500 items)\n",
       "[Text xxbos xxmaj there really are no redeeming factors about this show . xxmaj to put it simply , its just terrible . xxmaj absolutely dreadful . xxmaj it 's just a dreadful \" reality \" show . xxmaj not only that , it 's dreadful fiction . \n",
       "\n",
       " xxmaj imagine this : a bunch of overly - imaginative teenagers get together one night and go \" xxmaj hey ! xxmaj let 's make a paranormal show just like \" xxmaj ghost xxmaj hunters \" and whatnot ! \" xxmaj so they grab a camera , harass local residents and film random landscapes behind a painfully \" trying - to - be - dramatic - yet - failing - xxunk \" monologue . xxmaj this show is basically a bunch of teenagers running around with a home movie camera trying to make a really bad horror documentary . xxmaj the only difference is this show actually has a budget and writers . a wasted budget and terrible writers . \n",
       "\n",
       " xxmaj oh , the problems , how do i count thee ? xxmaj well , first off , let 's talk about this from a personal level . i am not a total skeptic when it comes to the paranormal . i am willing to believe in what s paranormal and what s not , and i 'm sure there are a lot of people who feel the same . xxmaj so , if you 're going to do a show about the paranormal , you have to do a good job convincing the viewer that what they 're seeing is either paranormal or not , because the viewer can easily believe otherwise . i hate to compare , but i do n't see why not at this point . xxmaj take \" xxmaj ghost xxmaj hunters \" for example . xxmaj in \" xxmaj ghost xxmaj hunters \" you can tell that the cast is leveled with the audience . xxmaj they 're not totally skeptical , yet they 're still willing to keep the possibility of any paranormal anomalies in mind . xxmaj they have to look at something and be willing to say \" this is possible that its simply nothing \" . xxmaj and , with that in mind , they set out to try and prove themselves wrong . xxmaj they use technology and several other gadgets along with constant moderation to determine what is paranormal along with bearing the fact that what they may be monitoring could be nothing in mind . xxmaj not only are they trying to convince themselves what is real and what is not , in the process they are trying to convince you . xxmaj that element of doubt is not present in \" xxmaj paranormal xxmaj state \" . xxmaj strike one . \n",
       "\n",
       " xxmaj in \" xxmaj paranormal xxmaj state \" , the cast simply says \" there 's this spooky place , and its xxup haunted , so we 're going to find some xxup spirits ! \" xxmaj and immediately you know and saying to yourself \" xxmaj okay , convince me otherwise \" . xxmaj the cast is not professional in their interviews . xxmaj in fact , sometimes it seems like they 're just harassing local residents of these so - called \" haunted \" areas . xxmaj they have no real evidence to back up their claims besides assumptions and theories , and the best they can must up is somebody who \" claims \" they can contact the dead , with no one ever backing up who this person is and how valid they really are . xxmaj they could have easily just picked some random person off the street and said \" pretend you can contact spirits for our show \" and went at it . xxmaj in the \" xxmaj xxunk \" episode , this just happens . xxmaj without any convincing evidence towards the end of the show , they bring this sort of individual out where he does a random , painfully scripted \" reading \" of a supposed area of how something is \" haunted \" in order to convince its audience . xxmaj very , very poor effort . i feel that one of the main problems with the show is that it feels scripted . xxmaj during one of the episodes , the cast gets attacked by one of these \" paranormal anomalies \" at times in an attempt to be dramatic . xxmaj these sort of dramatic sequences would make any skeptic laugh and even those who are on the fence realize what they 're watching is just a bunch of tabloid - esquire trash . xxmaj if the show 's aim was to try and convince their audience that these \" paranormal \" events are real , they 're doing a horrifically poor job at doing so . xxmaj strike two . \n",
       "\n",
       " xxmaj however , there is always the counter . xxmaj just one last viewpoint to see if the show is actually worth something . xxmaj what if the show is n't trying to convince you that these paranormal events are real and are simply trying to entertain you with good fiction ? xxmaj it even fails on that level as well . xxmaj if the show 's creators were trying to craft fiction to entertain its audience , the writing is too poor and even on a fictional level , it fails to convince the audience that its cast members are really experiencing the unknown in all its full , horrifying glory . xxmaj the writing is simply not compelling and even , dare i say , boring . xxmaj strike three . \n",
       "\n",
       " xxmaj so what remains of this show is simply a bunch of teenagers who are too willing or too gullible to believe in the paranormal simply because its simply much more amazing than reality who set out with a camera , a bad script and bad actors to generally just make a really bad horror documentary . xxmaj that s all the show is at this point . xxmaj there is no reason to see it , not even for the entertainment factor , and there 's no reason to care about it . xxmaj to be blunt , its lame . xxmaj there are absolutely no redeeming factors about this show ., Text xxbos a moderately interesting start , some pretty scenes in sixteenth - century xxmaj japan , and a promising idea . xxmaj but the execution ? xxmaj the comparison that springs to mind after about fifteen minutes is \" xxmaj cannibal xxmaj women in the xxmaj xxunk xxmaj jungle of xxmaj death . \" xxmaj really . a specialist in \" xxmaj oriental history \" who does n't speak any xxmaj japanese , walks on xxunk without removing her shoes , and is generally dumb as celery ? xxmaj please . xxmaj this looks like a student film : the sets are risible , the acting ( except , perhaps , for the title character ) close to wooden , the plot utterly arbitrary . xxmaj at least \" xxmaj cannibal xxmaj women \" was funny ! xxmaj this is best watched with someone who knows something about xxmaj japan , just to watch disbelief repeatedly crawl across their face ., Text xxbos i kind of like xxup jag . xxmaj it do have it´s charm but lately it´s to much propaganda in it . xxmaj for an outsider ( a non xxmaj american ) the patriotic feeling can be a bit to much . \n",
       "\n",
       " i don´t like that xxmaj rabb and mackenzie goes from being lawyers ( as they were in the early parts of the xxup tv show ) to become super heros that stops wars and rescues entire continents . xxmaj its almost like watching a recruitment video from the xxup us army . \n",
       "\n",
       " i still watch the show , so it´s not that bad . xxmaj but i would prefer more episodes when xxmaj rabb and mackenzie investigates military accidents and don´t save the world in the future ., Text xxbos xxmaj there is a famous short story about a man who becomes the prey of a safari hunter who has lost interest in hunting anything except humans . xxmaj its quite good , and its been done and redone in film and xxup tv many many times . xxmaj some are notable , but this xxunk version , that injects the tired old racism themes , just flat out stinks . xxmaj leguizamo 's slapstick is almost as weak as the unfunny script . xxmaj chaplin , this guy is n't . xxmaj there must be people who find a dwarf who ca nt stop dancing funny , i mean i suppose it is funny in a pathetic freakish way , but its just not enough to carry a movie . xxmaj you have the usual xxmaj nazi xxunk or neo - xxmaj nazi whatever the heck we are supposed to think , type villain , who 's son of course is gay , xxmaj german accents ... get the picture ?, Text xxbos xxmaj this comes close to the worst movie i 've ever seen . xxmaj the writer starts you out in a way that you 'll side with xxmaj jasper ( xxmaj josh xxmaj hartnett ) . xxmaj when he did absolutely nothing wrong , xxmaj sam ( xxmaj leelee xxmaj sobiesky ) leaves him for xxmaj kelley ( xxmaj chris xxmaj klein ) , in a way that leaves you mad at xxmaj sam . xxmaj you are n't let in on what she feels , so her feelings with xxmaj kelley are n't real to you , and their relationship is phony . xxmaj it drags you in either direction , and it gets rather exhausting and annoying . xxmaj the only good thing about this movie that i saw was the cast . \n",
       "\n",
       "]...\n",
       "Path: /data/imdb;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (2500 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: /data/imdb\n",
       "x: LMTextList (2500 items)\n",
       "[Text xxbos xxmaj well , i 'm a huge fan and follower of xxmaj elizabeth xxmaj berkley . i bought this on xxup dvd off of ebay for my boyfriends birthday . xxmaj we sat down to watch it and it was so boring . i do n't remember laughing once . xxmaj it 's only on for about an hour and half and it seemed to take forever to end . xxmaj elizabeth is great in this though . xxmaj maybe it 's just because i 'm a big xxmaj elizabeth xxmaj berkley fan though . xxmaj if she was n't in it i would n't have watched it but every time she came on my face lit up . xxmaj unfortunately even xxmaj elizabeth could n't save this film . xxmaj just the overall story and awful comedy makes this a film you 'd rather miss than waste an hour and a half of your life . xxmaj it 's a very forgetful film ., Text xxbos holy sweet murder this is quite possibly the least funny movie i 've ever seen . you can take my word for this as truth because it 's playing on television right now . it 's really one of the most pathetic productions i 've ever seen . there is not a single redeemable aspect of this flick . it just lacks any humor whatsoever . the only good thing it possibly has going for it is that it 's so unfunny that it 's wholly unmemorable . in fact , i just sat through some ridiculous sub - plot and i ca n't really tell you what went on . the only reason i can even possibly remember having seen this movie is because it 's so absolutely humorless it will stick in my mind forever based on that alone . \n",
       "\n",
       " an absolutely must miss . if your friend wants to show it to you , shoot him and save yourself the boredom ., Text xxbos xxmaj telly xxmaj savalas put on a passable ( but no better than that ) performance as xxmaj xxunk xxmaj villa , the notorious xxmaj mexican bandit / revolutionary in this account of xxmaj villa 's raid on the town of xxmaj columbus , xxmaj new xxmaj mexico in 1916 . xxmaj villa is not really a historical figure who i 'm overly familiar with , so i wo n't say much about the historical details of the film . xxmaj as a movie , this is n't great , although it has a smattering here and there of both action and humour . xxmaj chuck xxmaj connors ' performance as xxmaj colonel xxmaj xxunk , commander of the xxup u.s. xxmaj army base near xxmaj columbus struck me as a bit over the top , and xxmaj clint xxmaj walker as xxmaj villa 's xxmaj xxunk sidekick xxmaj scotty did n't really do very much for me . xxmaj the movie is obviously a pretty low budget effort of limited technical quality . xxmaj for a movie with a runtime of only slightly over an hour and a half i have to say that this movie dragged in places , particularly in the last 20 minutes or so . xxmaj villa 's raid into the xxmaj united xxmaj states was an interesting ( if , in the overall scheme of things , not especially important ) historical xxunk , and probably deserved better treatment than this . 4 / 10, Text xxbos xxup ok , let me start off by saying this is n't a horrible movie by any means . xxmaj it 's just not good . i recall one poster saying the acting is n't campy it 's just nuanced . xxmaj no . i 've seen nuanced xxmaj japanese and xxmaj asian acting . i 'm sorry , you 're wrong . xxmaj this is camp . \n",
       "\n",
       " xxmaj the characters are totally unsympathetic , the deaths are totally random and utterly meaningless . xxmaj the writing is bad . i 'm fine with suspending disbelief , i 'm fine with not having everything handed to me in terms of plot . xxmaj but this movie has no plot . xxmaj one reviewer stated \" xxmaj this movie is set in a small town where people are going nuts over xxunk and spirals . \" xxmaj that 's not a blurb , that 's the entire freaking film . xxmaj congratulations , i 've just saved you nearly an hour and a half . xxmaj there is nothing more to it . xxmaj no character development , no plot development , no explanations , no resolution . xxmaj and not even the \" xxmaj acceptable within the realm of j - xxmaj horror \" lack of resolution . xxmaj just nothing . \n",
       "\n",
       " xxmaj in addition , the musical score is done by someone who obviously was n't actually watching the movie at the time because it 's random enough to cause xxunk . xxmaj xxunk xxunk is one thing and done well it can be brilliant ( see xxmaj dark xxmaj water ) , but here it just seems as if the score was designed to go with another movie all together . \n",
       "\n",
       " xxmaj the best example i can give is it 's as if the xxmaj japanese remade xxmaj evil xxmaj dead without any of the clever bits or good acting . xxmaj it just falls flat . xxmaj it 's j - horror without the horror ., Text xxbos xxmaj boasting the title for the sickest film ever made , xxup pink xxup flamingos is an undisputed classic . xxmaj sure , the camerawork is shaky and off - center , the story is muddled and slow - paced , and every single character in the movie is repugnant and despicable , but xxup pink xxup flamingos has a certain playful charm and brilliant satiric wit that no other movie can match . \n",
       "\n",
       " xxmaj while this film is indeed an offensive one , reading descriptions of what goes on in the movie is much worse than actually seeing it . xxmaj only xxmaj john xxmaj waters can succeed in making rape , murder , sadism , cannibalism , xxunk , and just about every other form of human debauchery known to man seem absolutely hilarious . xxmaj this movie must be seen to be believed .]...\n",
       "Path: /data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(36258, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(36258, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=36258, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb64ebe8620>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/data/imdb'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(36258, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(36258, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=36258, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])\n",
       "bptt: 70\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(36258, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(36258, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=36258, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"1.layers.0.weight\", \"1.layers.0.bias\", \"1.layers.0.running_mean\", \"1.layers.0.running_var\", \"1.layers.2.weight\", \"1.layers.2.bias\", \"1.layers.4.weight\", \"1.layers.4.bias\", \"1.layers.4.running_mean\", \"1.layers.4.running_var\", \"1.layers.6.weight\", \"1.layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"1.decoder.weight\", \"1.decoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-44585e99aeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fine_tuned'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name, device, strict, with_opt)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{name}.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tMissing key(s) in state_dict: \"1.layers.0.weight\", \"1.layers.0.bias\", \"1.layers.0.running_mean\", \"1.layers.0.running_var\", \"1.layers.2.weight\", \"1.layers.2.bias\", \"1.layers.4.weight\", \"1.layers.4.bias\", \"1.layers.4.running_mean\", \"1.layers.4.running_var\", \"1.layers.6.weight\", \"1.layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"1.decoder.weight\", \"1.decoder.bias\". "
     ]
    }
   ],
   "source": [
    "learn.load('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thats dumb and not at all . xxup lol . xxmaj it 's just true , if the person has been xxup accused of being a xxmaj jew , then the case is just that . xxmaj you should be ashamed of yourself ! xxbos i\n",
      "Thats dumb and not at all . xxmaj no more xxup than xxup you xxup like xxmaj your xxup bloody xxup school xxup sucks , xxup you xxup suck xxup bastard . xxbos xxup hello xxup my xxup name xxup is xxup the xxup name xxup\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Thats dumb and not at all\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a great point ! ! ! xxmaj of course , all the information is correct , the page is about the person and you are n't the only one that is taken seriously . xxmaj that 's it . xxmaj the article should\n",
      "What a great point ! \" xxbos xxmaj the xxmaj love xxmaj of xxmaj the xxmaj love ? \n",
      "\n",
      " xxmaj we were the only ones who thought the xxmaj love xxmaj song band was the best and the best side that xxmaj crazy xxmaj\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"What a great point\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error I got after running the whole thing on to_fp16()\n",
    "\n",
    "    ---------------------------------------------------------------------------\n",
    "    RuntimeError                              Traceback (most recent call last)\n",
    "    <ipython-input-56-135dd315cd3b> in <module>\n",
    "    ----> 1 print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))\n",
    "\n",
    "    <ipython-input-56-135dd315cd3b> in <genexpr>(.0)\n",
    "    ----> 1 print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))\n",
    "\n",
    "    /opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/text/learner.py in predict(self, text, n_words, no_unk, temperature, min_p)\n",
    "        100             if min_p is not None: res[res < min_p] = 0.\n",
    "        101             if temperature != 1.: res.pow_(1 / temperature)\n",
    "    --> 102             idx = torch.multinomial(res, 1).item()\n",
    "        103             text += f' {self.data.vocab.itos[idx]}'\n",
    "        104         return text\n",
    "\n",
    "    RuntimeError: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /opt/conda/conda-bld/pytorch_1544174967633/work/aten/src/TH/generic/THTensorRandom.cpp:298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to save the model but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('toxic_lm_finetuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('toxic_mc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = TextClasDataBunch.load(path, 'toxic_mc', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='90%'>  <col width='10%'>  <tr>\n",
       "    <th>text</th>\n",
       "    <th>target</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</th>\n",
       "    <th>pos</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj heavy - handed xxunk . xxmaj writers using characters as xxunk to speak for themselves . xxmaj predictable , plodding plot points ( say that five times fast ) . a child 's imitation of xxmaj britney xxmaj spears . xxmaj this film has all the earmarks of a xxmaj lifetime xxmaj special reject . \\n\\n i honestly believe that xxmaj jesus xxmaj xxunk and xxmaj julia xxmaj</th>\n",
       "    <th>neg</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj god ! xxmaj zorro has been the the subject of about as many movies as xxmaj tarzan , and probably had about as many actors in the title role . \\n\\n xxmaj this xxmaj serial is one of my own personal favourites , and as previously stated , it is one of the xxmaj top 5 xxmaj sound xxmaj serials . xxmaj oddly enough , this is one</th>\n",
       "    <th>pos</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxmaj first off , let me say that i am a great believer in xxmaj xxunk stuff . i see it as a way to continue a good show long after it has been cancelled . xxmaj star xxmaj trek xxmaj xxunk and xxmaj star xxmaj wars xxmaj revelations are examples of decent efforts . xxmaj so i have a soft - spot for xxunk stuff that means i</th>\n",
       "    <th>neg</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>xxbos xxrep 5 * xxup warning , xxup may xxup contain xxup spoilers xxup which xxup will xxup be xxup more xxup entertaining xxup than xxup this xxup tripe . xxrep 4 * \\n\\n xxmaj heres some good advise to anyone living in the xxup u.k. xxmaj whenever xxmaj channel 5 has an old 80 's comedy on late at night , read a book instead . i am currently</th>\n",
       "    <th>neg</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_test_enc')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 06:53 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.409948</th>\n",
       "    <th>0.245562</th>\n",
       "    <th>0.904160</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned_test_cls_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned_test_cls_1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 08:41 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.308999</th>\n",
       "    <th>0.202802</th>\n",
       "    <th>0.922640</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned_test_cls_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned_test_cls_2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='1041', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 51.00 MiB (GPU 0; 5.93 GiB total capacity; 4.73 GiB already allocated; 30.12 MiB free; 345.27 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-644a31004af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     21\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 178\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtb_clear_frames\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ref_free_exc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# must!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0;31m# re-raises the exact last exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtb_clear_frames\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 51.00 MiB (GPU 0; 5.93 GiB total capacity; 4.73 GiB already allocated; 30.12 MiB free; 345.27 MiB cached)"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 15:17 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.240424</th>\n",
       "    <th>0.155204</th>\n",
       "    <th>0.943160</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.217462</th>\n",
       "    <th>0.153421</th>\n",
       "    <th>0.943960</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([7.5928e-04, 9.9924e-01]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
